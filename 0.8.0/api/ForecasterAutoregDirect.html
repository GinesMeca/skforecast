
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="Python library that eases using scikit-learn regressors as multi-step forecasters. It also works with any regressor compatible with the scikit-learn API (XGBoost, LightGBM, Ranger...).">
      
      
        <meta name="author" content="Joaquin Amat Rodrigo and Javier Escobar Ortiz">
      
      
        <link rel="canonical" href="https://joaquinamatrodrigo.github.io/skforecast/0.8.0/api/ForecasterAutoregDirect.html">
      
      <link rel="icon" href="../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.3.1, mkdocs-material-8.5.3">
    
    
      
        <title>ForecasterAutoregDirect - Skforecast Docs</title>
      
    
    
      <link rel="stylesheet" href="../assets/stylesheets/main.7a952b86.min.css">
      
        
        <link rel="stylesheet" href="../assets/stylesheets/palette.cbb835fc.min.css">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,700,700i%7CUbuntu+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Open Sans";--md-code-font:"Ubuntu Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../stylesheets/extra.css">
    
    <script>__md_scope=new URL("..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      
  


  
  


  <script id="__analytics">function __md_analytics(){function n(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],n("js",new Date),n("config","G-GR8X9Z9LKL"),document.addEventListener("DOMContentLoaded",function(){document.forms.search&&document.forms.search.query.addEventListener("blur",function(){this.value&&n("event","search",{search_term:this.value})}),document$.subscribe(function(){var a=document.forms.feedback;if(void 0!==a)for(var e of a.querySelectorAll("[type=submit]"))e.addEventListener("click",function(e){e.preventDefault();var t=document.location.pathname,e=this.getAttribute("data-md-value");n("event","feedback",{page:t,data:e}),a.firstElementChild.disabled=!0;e=a.querySelector(".md-feedback__note [data-md-value='"+e+"']");e&&(e.hidden=!1)}),a.hidden=!1}),location$.subscribe(function(e){n("config","G-GR8X9Z9LKL",{page_path:e.pathname})})});var e=document.createElement("script");e.async=!0,e.src="https://www.googletagmanager.com/gtag/js?id=G-GR8X9Z9LKL",document.getElementById("__analytics").insertAdjacentElement("afterEnd",e)}</script>

  
    <script>var consent;"undefined"==typeof __md_analytics||(consent=__md_get("__consent"))&&consent.analytics&&__md_analytics()</script>
  

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="light" data-md-color-primary="" data-md-color-accent="">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#forecasterautoregdirect" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
      <div data-md-component="outdated" hidden>
        
          <aside class="md-banner md-banner--warning">
            <div class="md-banner__inner md-grid md-typeset">
              
  You're not viewing the latest version.
  <a href="../..">
    <strong>Click here to go to latest.</strong>
  </a>

            </div>
            <script>var el=document.querySelector("[data-md-component=outdated]"),outdated=__md_get("__outdated",sessionStorage);!0===outdated&&el&&(el.hidden=!1)</script>
          </aside>
        
      </div>
    
    
      

  

<header class="md-header md-header--lifted" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href=".." title="Skforecast Docs" class="md-header__button md-logo" aria-label="Skforecast Docs" data-md-component="logo">
      
  <img src="../img/logo-skforecast-orange-no-backgound.png" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            Skforecast Docs
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              ForecasterAutoregDirect
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme)" data-md-color-scheme="light" data-md-color-primary="" data-md-color-accent=""  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="" data-md-color-accent=""  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/JoaquinAmatRodrigo/skforecast" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
      </div>
    
  </nav>
  
    
      
<nav class="md-tabs" aria-label="Tabs" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../index.html" class="md-tabs__link">
        Home
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../introduction-forecasting/introduction-forecasting.html" class="md-tabs__link">
        Introduction to forecasting
      </a>
    </li>
  

      
        
  
  


  <li class="md-tabs__item">
    <a href="../user_guides/quick-start-skforecast.html" class="md-tabs__link">
      Quick start
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../user_guides/input-data.html" class="md-tabs__link">
        User Guides
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../examples/examples.html" class="md-tabs__link">
        Examples and tutorials
      </a>
    </li>
  

      
        
  
  
    
  


  
  
  
    <li class="md-tabs__item">
      <a href="ForecasterAutoreg.html" class="md-tabs__link md-tabs__link--active">
        API Reference
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../faq/faq.html" class="md-tabs__link">
        FAQ and Tips
      </a>
    </li>
  

      
        
  
  


  <li class="md-tabs__item">
    <a href="../releases/releases.html" class="md-tabs__link">
      Releases
    </a>
  </li>

      
    </ul>
  </div>
</nav>
    
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href=".." title="Skforecast Docs" class="md-nav__button md-logo" aria-label="Skforecast Docs" data-md-component="logo">
      
  <img src="../img/logo-skforecast-orange-no-backgound.png" alt="logo">

    </a>
    Skforecast Docs
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/JoaquinAmatRodrigo/skforecast" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M439.55 236.05 244 40.45a28.87 28.87 0 0 0-40.81 0l-40.66 40.63 51.52 51.52c27.06-9.14 52.68 16.77 43.39 43.68l49.66 49.66c34.23-11.8 61.18 31 35.47 56.69-26.49 26.49-70.21-2.87-56-37.34L240.22 199v121.85c25.3 12.54 22.26 41.85 9.08 55a34.34 34.34 0 0 1-48.55 0c-17.57-17.6-11.07-46.91 11.25-56v-123c-20.8-8.51-24.6-30.74-18.64-45L142.57 101 8.45 235.14a28.86 28.86 0 0 0 0 40.81l195.61 195.6a28.86 28.86 0 0 0 40.8 0l194.69-194.69a28.86 28.86 0 0 0 0-40.81z"/></svg>
  </div>
  <div class="md-source__repository">
    GitHub
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_1" type="checkbox" id="__nav_1" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_1">
          Home
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Home" data-md-level="1">
        <label class="md-nav__title" for="__nav_1">
          <span class="md-nav__icon md-icon"></span>
          Home
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../index.html" class="md-nav__link">
        Welcome to skforecast
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../introduction-forecasting/introduction-forecasting.html" class="md-nav__link">
        Introduction to forecasting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/quick-start-skforecast.html" class="md-nav__link">
        Quick start
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/input-data.html" class="md-nav__link">
        User Guides
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../examples/examples.html" class="md-nav__link">
        Examples and tutorials
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ForecasterAutoreg.html" class="md-nav__link">
        API Reference
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../faq/faq.html" class="md-nav__link">
        FAQ and Tips
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../releases/releases.html" class="md-nav__link">
        Releases
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_2">
          Introduction to forecasting
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Introduction to forecasting" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Introduction to forecasting
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../introduction-forecasting/introduction-forecasting.html" class="md-nav__link">
        Introduction to forecasting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../introduction-forecasting/forecaster-parameters.html" class="md-nav__link">
        Forecaster Parameters
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../introduction-forecasting/forecaster-attributes.html" class="md-nav__link">
        Forecaster Attributes
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/quick-start-skforecast.html" class="md-nav__link">
        Quick start
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_4">
          User Guides
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="User Guides" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          User Guides
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/input-data.html" class="md-nav__link">
        Input data
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/autoregresive-forecaster.html" class="md-nav__link">
        Recursive multi-step forecasting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/direct-multi-step-forecasting.html" class="md-nav__link">
        Direct multi-step forecasting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/independent-multi-time-series-forecasting.html" class="md-nav__link">
        Independent multi-time series forecasting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/dependent-multi-series-multivariate-forecasting.html" class="md-nav__link">
        Dependent multivariate series forecasting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/exogenous-variables.html" class="md-nav__link">
        Exogenous variables
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/custom-predictors.html" class="md-nav__link">
        Custom predictors
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/weighted-time-series-forecasting.html" class="md-nav__link">
        Weighted time series forecasting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/backtesting.html" class="md-nav__link">
        Backtesting forecaster
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/hyperparameter-tuning-and-lags-selection.html" class="md-nav__link">
        Hyperparameter tuning and lags selection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/sklearn-transformers-and-pipeline.html" class="md-nav__link">
        Scikit-learn Transformers and Pipelines
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/probabilistic-forecasting.html" class="md-nav__link">
        Probabilistic forecasting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/feature-importances.html" class="md-nav__link">
        Feature importances
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/categorical-features.html" class="md-nav__link">
        Categorical features
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/forecasting-xgboost-lightgbm.html" class="md-nav__link">
        Forecasting with XGBoost and LightGBM
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/forecasting-sarimax-arima.html" class="md-nav__link">
        Forecasting SARIMAX and ARIMA models
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/save-load-forecaster.html" class="md-nav__link">
        Save and load forecaster
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/forecaster-in-production.html" class="md-nav__link">
        Forecaster in production
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/shap-values-skforecast.html" class="md-nav__link">
        Shap-values
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/skforecast-in-GPU.html" class="md-nav__link">
        Skforecast in GPU
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../user_guides/plot-forecaster-residuals.html" class="md-nav__link">
        Plot forecaster residuals
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_5">
          Examples and tutorials
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="Examples and tutorials" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          Examples and tutorials
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../examples/examples.html" class="md-nav__link">
        Examples and tutorials
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_6">
          API Reference
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="API Reference" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          API Reference
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ForecasterAutoreg.html" class="md-nav__link">
        ForecasterAutoreg
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ForecasterAutoregCustom.html" class="md-nav__link">
        ForecasterAutoregCustom
      </a>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" data-md-toggle="toc" type="checkbox" id="__toc">
      
      
        
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          ForecasterAutoregDirect
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="ForecasterAutoregDirect.html" class="md-nav__link md-nav__link--active">
        ForecasterAutoregDirect
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect" class="md-nav__link">
    ForecasterAutoregDirect
  </a>
  
    <nav class="md-nav" aria-label="ForecasterAutoregDirect">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.create_sample_weights" class="md-nav__link">
    create_sample_weights()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.create_train_X_y" class="md-nav__link">
    create_train_X_y()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.filter_train_X_y_for_step" class="md-nav__link">
    filter_train_X_y_for_step()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.fit" class="md-nav__link">
    fit()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.get_feature_importance" class="md-nav__link">
    get_feature_importance()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.get_feature_importances" class="md-nav__link">
    get_feature_importances()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict" class="md-nav__link">
    predict()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict_bootstrapping" class="md-nav__link">
    predict_bootstrapping()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict_dist" class="md-nav__link">
    predict_dist()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict_interval" class="md-nav__link">
    predict_interval()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict_pandas" class="md-nav__link">
    predict_pandas()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.set_fit_kwargs" class="md-nav__link">
    set_fit_kwargs()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.set_lags" class="md-nav__link">
    set_lags()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.set_out_sample_residuals" class="md-nav__link">
    set_out_sample_residuals()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.set_params" class="md-nav__link">
    set_params()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoreg.ForecasterAutoreg.ForecasterAutoreg._create_lags" class="md-nav__link">
    _create_lags()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoreg.ForecasterAutoreg.ForecasterAutoreg.__repr__" class="md-nav__link">
    __repr__()
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ForecasterMultiSeries.html" class="md-nav__link">
        ForecasterMultiSeries
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ForecasterMultiSeriesCustom.html" class="md-nav__link">
        ForecasterMultiSeriesCustom
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ForecasterMultiVariate.html" class="md-nav__link">
        ForecasterMultiVariate
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="ForecasterSarimax.html" class="md-nav__link">
        ForecasterSarimax
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="model_selection.html" class="md-nav__link">
        model_selection
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="model_selection_multiseries.html" class="md-nav__link">
        model_selection_multiseries
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="model_selection_sarimax.html" class="md-nav__link">
        model_selection_sarimax
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="plot.html" class="md-nav__link">
        plot
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="utils.html" class="md-nav__link">
        utils
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="exceptions.html" class="md-nav__link">
        exceptions
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_7" type="checkbox" id="__nav_7" checked>
      
      
      
      
        <label class="md-nav__link" for="__nav_7">
          FAQ and Tips
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="FAQ and Tips" data-md-level="1">
        <label class="md-nav__title" for="__nav_7">
          <span class="md-nav__icon md-icon"></span>
          FAQ and Tips
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../faq/faq.html" class="md-nav__link">
        Table of contents
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../faq/profiling-skforecast.html" class="md-nav__link">
        Profiling skforecast
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../faq/non-negative-predictions.html" class="md-nav__link">
        Avoid negative predictions when forecasting
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../faq/forecasting-time-series-with-missing-values.html" class="md-nav__link">
        Forecasting time series with missing values
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../releases/releases.html" class="md-nav__link">
        Releases
      </a>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
    
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect" class="md-nav__link">
    ForecasterAutoregDirect
  </a>
  
    <nav class="md-nav" aria-label="ForecasterAutoregDirect">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.create_sample_weights" class="md-nav__link">
    create_sample_weights()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.create_train_X_y" class="md-nav__link">
    create_train_X_y()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.filter_train_X_y_for_step" class="md-nav__link">
    filter_train_X_y_for_step()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.fit" class="md-nav__link">
    fit()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.get_feature_importance" class="md-nav__link">
    get_feature_importance()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.get_feature_importances" class="md-nav__link">
    get_feature_importances()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict" class="md-nav__link">
    predict()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict_bootstrapping" class="md-nav__link">
    predict_bootstrapping()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict_dist" class="md-nav__link">
    predict_dist()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict_interval" class="md-nav__link">
    predict_interval()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict_pandas" class="md-nav__link">
    predict_pandas()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.set_fit_kwargs" class="md-nav__link">
    set_fit_kwargs()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.set_lags" class="md-nav__link">
    set_lags()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.set_out_sample_residuals" class="md-nav__link">
    set_out_sample_residuals()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.set_params" class="md-nav__link">
    set_params()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoreg.ForecasterAutoreg.ForecasterAutoreg._create_lags" class="md-nav__link">
    _create_lags()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#skforecast.ForecasterAutoreg.ForecasterAutoreg.ForecasterAutoreg.__repr__" class="md-nav__link">
    __repr__()
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  <a href="https://github.com/JoaquinAmatRodrigo/skforecast/edit/master/docs/api/ForecasterAutoregDirect.md" title="Edit this page" class="md-content__button md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>


<h1 id="forecasterautoregdirect"><code>ForecasterAutoregDirect</code><a class="headerlink" href="#forecasterautoregdirect" title="Permanent link">&para;</a></h1>


  <div class="doc doc-object doc-class">



<h2 id="skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect" class="doc doc-heading">
        <code>
ForecasterAutoregDirect            (<span title="skforecast.ForecasterBase.ForecasterBase.ForecasterBase">ForecasterBase</span>)
        </code>



<a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

      <p>This class turns any regressor compatible with the scikit-learn API into a</p>
<p>autoregressive direct multi-step forecaster. A separate model is created for
each forecast time step. See documentation for more details.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>regressor</code></td>
        <td><code>object</code></td>
        <td><p>An instance of a regressor or pipeline compatible with the scikit-learn API.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>lags</code></td>
        <td><code>Union[int, numpy.ndarray, list]</code></td>
        <td><p>Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.
    <code>int</code>: include lags from 1 to <code>lags</code> (included).
    <code>list</code>, <code>numpy ndarray</code> or range: include only lags present in <code>lags</code>.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>steps</code></td>
        <td><code>int</code></td>
        <td><p>Maximum number of future steps the forecaster will predict when using
method <code>predict()</code>. Since a different model is created for each step,
this value should be defined before training.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>transformer_y</code></td>
        <td><code>Optional[object]</code></td>
        <td><p>An instance of a transformer (preprocessor) compatible with the scikit-learn
preprocessing API with methods: fit, transform, fit_transform and inverse_transform.
ColumnTransformers are not allowed since they do not have inverse_transform method.
The transformation is applied to <code>y</code> before training the forecaster.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>transformer_exog</code></td>
        <td><code>Optional[object]</code></td>
        <td><p>An instance of a transformer (preprocessor) compatible with the scikit-learn
preprocessing API. The transformation is applied to <code>exog</code> before training the
forecaster. <code>inverse_transform</code> is not available when using ColumnTransformers.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>weight_func</code></td>
        <td><code>Optional[Callable]</code></td>
        <td><p>Function that defines the individual weights for each sample based on the
index. For example, a function that assigns a lower weight to certain dates.
Ignored if <code>regressor</code> does not have the argument <code>sample_weight</code> in its <code>fit</code>
method. The resulting <code>sample_weight</code> cannot have negative values.
<strong>New in version 0.6.0</strong></p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>fit_kwargs</code></td>
        <td><code>Optional[dict]</code></td>
        <td><p>Additional arguments to be passed to the <code>fit</code> method of the regressor.
<strong>New in version 0.8.0</strong></p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>forecaster_id</code></td>
        <td><code>Union[str, int]</code></td>
        <td><p>Name used as an identifier of the forecaster.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Attributes:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>regressor</code></td>
        <td><code>regressor or pipeline compatible with the scikit-learn API</code></td>
        <td><p>An instance of a regressor or pipeline compatible with the scikit-learn API.
An instance of this regressor is trained for each step. All of them 
are stored in <code>self.regressors_</code>.</p></td>
      </tr>
      <tr>
        <td><code>regressors_</code></td>
        <td><code>dict</code></td>
        <td><p>Dictionary with regressors trained for each step. They are initialized 
as a copy of <code>regressor</code>.</p></td>
      </tr>
      <tr>
        <td><code>steps</code></td>
        <td><code>int</code></td>
        <td><p>Number of future steps the forecaster will predict when using method
<code>predict()</code>. Since a different model is created for each step, this value
should be defined before training.</p></td>
      </tr>
      <tr>
        <td><code>lags</code></td>
        <td><code>numpy ndarray</code></td>
        <td><p>Lags used as predictors.</p></td>
      </tr>
      <tr>
        <td><code>transformer_y</code></td>
        <td><code>object transformer (preprocessor), default `None`</code></td>
        <td><p>An instance of a transformer (preprocessor) compatible with the scikit-learn
preprocessing API with methods: fit, transform, fit_transform and inverse_transform.
ColumnTransformers are not allowed since they do not have inverse_transform method.
The transformation is applied to <code>y</code> before training the forecaster.</p></td>
      </tr>
      <tr>
        <td><code>transformer_exog</code></td>
        <td><code>object transformer (preprocessor), default `None`</code></td>
        <td><p>An instance of a transformer (preprocessor) compatible with the scikit-learn
preprocessing API. The transformation is applied to <code>exog</code> before training the
forecaster. <code>inverse_transform</code> is not available when using ColumnTransformers.</p></td>
      </tr>
      <tr>
        <td><code>weight_func</code></td>
        <td><code>Callable</code></td>
        <td><p>Function that defines the individual weights for each sample based on the
index. For example, a function that assigns a lower weight to certain dates.
Ignored if <code>regressor</code> does not have the argument <code>sample_weight</code> in its <code>fit</code>
method.
<strong>New in version 0.6.0</strong></p></td>
      </tr>
      <tr>
        <td><code>source_code_weight_func</code></td>
        <td><code>str</code></td>
        <td><p>Source code of the custom function used to create weights.
<strong>New in version 0.6.0</strong></p></td>
      </tr>
      <tr>
        <td><code>max_lag</code></td>
        <td><code>int</code></td>
        <td><p>Maximum value of lag included in <code>lags</code>.</p></td>
      </tr>
      <tr>
        <td><code>window_size</code></td>
        <td><code>int</code></td>
        <td><p>Size of the window needed to create the predictors. It is equal to
<code>max_lag</code>.</p></td>
      </tr>
      <tr>
        <td><code>last_window</code></td>
        <td><code>pandas Series</code></td>
        <td><p>Last window the forecaster has seen during training. It stores the
values needed to predict the next <code>step</code> immediately after the training data.</p></td>
      </tr>
      <tr>
        <td><code>index_type</code></td>
        <td><code>type</code></td>
        <td><p>Type of index of the input used in training.</p></td>
      </tr>
      <tr>
        <td><code>index_freq</code></td>
        <td><code>str</code></td>
        <td><p>Frequency of Index of the input used in training.</p></td>
      </tr>
      <tr>
        <td><code>training_range</code></td>
        <td><code>pandas Index</code></td>
        <td><p>First and last values of index of the data used during training.</p></td>
      </tr>
      <tr>
        <td><code>included_exog</code></td>
        <td><code>bool</code></td>
        <td><p>If the forecaster has been trained using exogenous variable/s.</p></td>
      </tr>
      <tr>
        <td><code>exog_type</code></td>
        <td><code>type</code></td>
        <td><p>Type of exogenous variable/s used in training.</p></td>
      </tr>
      <tr>
        <td><code>exog_dtypes</code></td>
        <td><code>dict</code></td>
        <td><p>Type of each exogenous variable/s used in training. If <code>transformer_exog</code> 
is used, the dtypes are calculated after the transformation.</p></td>
      </tr>
      <tr>
        <td><code>exog_col_names</code></td>
        <td><code>list</code></td>
        <td><p>Names of columns of <code>exog</code> if <code>exog</code> used in training was a pandas
DataFrame.</p></td>
      </tr>
      <tr>
        <td><code>X_train_col_names</code></td>
        <td><code>list</code></td>
        <td><p>Names of columns of the matrix created internally for training.</p></td>
      </tr>
      <tr>
        <td><code>fit_kwargs</code></td>
        <td><code>dict</code></td>
        <td><p>Additional arguments to be passed to the <code>fit</code> method of the regressor.
<strong>New in version 0.8.0</strong></p></td>
      </tr>
      <tr>
        <td><code>in_sample_residuals</code></td>
        <td><code>dict</code></td>
        <td><p>Residuals of the models when predicting training data. Only stored up to
1000 values per model in the form <code>{step: residuals}</code>. If <code>transformer_y</code> 
is not <code>None</code>, residuals are stored in the transformed scale.</p></td>
      </tr>
      <tr>
        <td><code>out_sample_residuals</code></td>
        <td><code>dict</code></td>
        <td><p>Residuals of the models when predicting non training data. Only stored
up to 1000 values per model in the form <code>{step: residuals}</code>. If <code>transformer_y</code> 
is not <code>None</code>, residuals are assumed to be in the transformed scale. Use 
<code>set_out_sample_residuals()</code> method to set values.</p></td>
      </tr>
      <tr>
        <td><code>fitted</code></td>
        <td><code>bool</code></td>
        <td><p>Tag to identify if the regressor has been fitted (trained).</p></td>
      </tr>
      <tr>
        <td><code>creation_date</code></td>
        <td><code>str</code></td>
        <td><p>Date of creation.</p></td>
      </tr>
      <tr>
        <td><code>fit_date</code></td>
        <td><code>str</code></td>
        <td><p>Date of last fit.</p></td>
      </tr>
      <tr>
        <td><code>skforcast_version</code></td>
        <td><code>str</code></td>
        <td><p>Version of skforecast library used to create the forecaster.</p></td>
      </tr>
      <tr>
        <td><code>python_version</code></td>
        <td><code>str</code></td>
        <td><p>Version of python used to create the forecaster.</p></td>
      </tr>
      <tr>
        <td><code>forecaster_id</code></td>
        <td><code>str, int default `None`</code></td>
        <td><p>Name used as an identifier of the forecaster.</p></td>
      </tr>
      <tr>
        <td><code>fit_kwargs</code></td>
        <td><code>dict, default `None`</code></td>
        <td><p>Additional parameters passed to the <code>fit</code> method of the regressor.</p></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">class</span> <span class="nc">ForecasterAutoregDirect</span><span class="p">(</span><span class="n">ForecasterBase</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This class turns any regressor compatible with the scikit-learn API into a</span>
<span class="sd">    autoregressive direct multi-step forecaster. A separate model is created for</span>
<span class="sd">    each forecast time step. See documentation for more details.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    regressor : regressor or pipeline compatible with the scikit-learn API</span>
<span class="sd">        An instance of a regressor or pipeline compatible with the scikit-learn API.</span>

<span class="sd">    lags : int, list, 1d numpy ndarray, range</span>
<span class="sd">        Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.</span>
<span class="sd">            `int`: include lags from 1 to `lags` (included).</span>
<span class="sd">            `list`, `numpy ndarray` or range: include only lags present in `lags`.</span>

<span class="sd">    steps : int</span>
<span class="sd">        Maximum number of future steps the forecaster will predict when using</span>
<span class="sd">        method `predict()`. Since a different model is created for each step,</span>
<span class="sd">        this value should be defined before training.</span>

<span class="sd">    transformer_y : object transformer (preprocessor), default `None`</span>
<span class="sd">        An instance of a transformer (preprocessor) compatible with the scikit-learn</span>
<span class="sd">        preprocessing API with methods: fit, transform, fit_transform and inverse_transform.</span>
<span class="sd">        ColumnTransformers are not allowed since they do not have inverse_transform method.</span>
<span class="sd">        The transformation is applied to `y` before training the forecaster.</span>

<span class="sd">    transformer_exog : object transformer (preprocessor), default `None`</span>
<span class="sd">        An instance of a transformer (preprocessor) compatible with the scikit-learn</span>
<span class="sd">        preprocessing API. The transformation is applied to `exog` before training the</span>
<span class="sd">        forecaster. `inverse_transform` is not available when using ColumnTransformers.</span>

<span class="sd">    weight_func : Callable, default `None`</span>
<span class="sd">        Function that defines the individual weights for each sample based on the</span>
<span class="sd">        index. For example, a function that assigns a lower weight to certain dates.</span>
<span class="sd">        Ignored if `regressor` does not have the argument `sample_weight` in its `fit`</span>
<span class="sd">        method. The resulting `sample_weight` cannot have negative values.</span>
<span class="sd">        **New in version 0.6.0**</span>

<span class="sd">    fit_kwargs : dict, default `None`</span>
<span class="sd">        Additional arguments to be passed to the `fit` method of the regressor.</span>
<span class="sd">        **New in version 0.8.0**</span>

<span class="sd">    forecaster_id : str, int, default `None`</span>
<span class="sd">        Name used as an identifier of the forecaster.</span>

<span class="sd">    Attributes</span>
<span class="sd">    ----------</span>
<span class="sd">    regressor : regressor or pipeline compatible with the scikit-learn API</span>
<span class="sd">        An instance of a regressor or pipeline compatible with the scikit-learn API.</span>
<span class="sd">        An instance of this regressor is trained for each step. All of them </span>
<span class="sd">        are stored in `self.regressors_`.</span>

<span class="sd">    regressors_ : dict</span>
<span class="sd">        Dictionary with regressors trained for each step. They are initialized </span>
<span class="sd">        as a copy of `regressor`.</span>

<span class="sd">    steps : int</span>
<span class="sd">        Number of future steps the forecaster will predict when using method</span>
<span class="sd">        `predict()`. Since a different model is created for each step, this value</span>
<span class="sd">        should be defined before training.</span>

<span class="sd">    lags : numpy ndarray</span>
<span class="sd">        Lags used as predictors.</span>

<span class="sd">    transformer_y : object transformer (preprocessor), default `None`</span>
<span class="sd">        An instance of a transformer (preprocessor) compatible with the scikit-learn</span>
<span class="sd">        preprocessing API with methods: fit, transform, fit_transform and inverse_transform.</span>
<span class="sd">        ColumnTransformers are not allowed since they do not have inverse_transform method.</span>
<span class="sd">        The transformation is applied to `y` before training the forecaster.</span>

<span class="sd">    transformer_exog : object transformer (preprocessor), default `None`</span>
<span class="sd">        An instance of a transformer (preprocessor) compatible with the scikit-learn</span>
<span class="sd">        preprocessing API. The transformation is applied to `exog` before training the</span>
<span class="sd">        forecaster. `inverse_transform` is not available when using ColumnTransformers.</span>

<span class="sd">    weight_func : Callable</span>
<span class="sd">        Function that defines the individual weights for each sample based on the</span>
<span class="sd">        index. For example, a function that assigns a lower weight to certain dates.</span>
<span class="sd">        Ignored if `regressor` does not have the argument `sample_weight` in its `fit`</span>
<span class="sd">        method.</span>
<span class="sd">        **New in version 0.6.0**</span>

<span class="sd">    source_code_weight_func : str</span>
<span class="sd">        Source code of the custom function used to create weights.</span>
<span class="sd">        **New in version 0.6.0**</span>

<span class="sd">    max_lag : int</span>
<span class="sd">        Maximum value of lag included in `lags`.</span>

<span class="sd">    window_size : int</span>
<span class="sd">        Size of the window needed to create the predictors. It is equal to</span>
<span class="sd">        `max_lag`.</span>

<span class="sd">    last_window : pandas Series</span>
<span class="sd">        Last window the forecaster has seen during training. It stores the</span>
<span class="sd">        values needed to predict the next `step` immediately after the training data.</span>

<span class="sd">    index_type : type</span>
<span class="sd">        Type of index of the input used in training.</span>

<span class="sd">    index_freq : str</span>
<span class="sd">        Frequency of Index of the input used in training.</span>

<span class="sd">    training_range : pandas Index</span>
<span class="sd">        First and last values of index of the data used during training.</span>

<span class="sd">    included_exog : bool</span>
<span class="sd">        If the forecaster has been trained using exogenous variable/s.</span>

<span class="sd">    exog_type : type</span>
<span class="sd">        Type of exogenous variable/s used in training.</span>

<span class="sd">    exog_dtypes : dict</span>
<span class="sd">        Type of each exogenous variable/s used in training. If `transformer_exog` </span>
<span class="sd">        is used, the dtypes are calculated after the transformation.</span>

<span class="sd">    exog_col_names : list</span>
<span class="sd">        Names of columns of `exog` if `exog` used in training was a pandas</span>
<span class="sd">        DataFrame.</span>

<span class="sd">    X_train_col_names : list</span>
<span class="sd">        Names of columns of the matrix created internally for training.</span>

<span class="sd">    fit_kwargs : dict</span>
<span class="sd">        Additional arguments to be passed to the `fit` method of the regressor.</span>
<span class="sd">        **New in version 0.8.0**</span>

<span class="sd">    in_sample_residuals : dict</span>
<span class="sd">        Residuals of the models when predicting training data. Only stored up to</span>
<span class="sd">        1000 values per model in the form `{step: residuals}`. If `transformer_y` </span>
<span class="sd">        is not `None`, residuals are stored in the transformed scale.</span>

<span class="sd">    out_sample_residuals : dict</span>
<span class="sd">        Residuals of the models when predicting non training data. Only stored</span>
<span class="sd">        up to 1000 values per model in the form `{step: residuals}`. If `transformer_y` </span>
<span class="sd">        is not `None`, residuals are assumed to be in the transformed scale. Use </span>
<span class="sd">        `set_out_sample_residuals()` method to set values.</span>

<span class="sd">    fitted : bool</span>
<span class="sd">        Tag to identify if the regressor has been fitted (trained).</span>

<span class="sd">    creation_date : str</span>
<span class="sd">        Date of creation.</span>

<span class="sd">    fit_date : str</span>
<span class="sd">        Date of last fit.</span>

<span class="sd">    skforcast_version : str</span>
<span class="sd">        Version of skforecast library used to create the forecaster.</span>

<span class="sd">    python_version : str</span>
<span class="sd">        Version of python used to create the forecaster.</span>

<span class="sd">    forecaster_id : str, int default `None`</span>
<span class="sd">        Name used as an identifier of the forecaster.</span>

<span class="sd">    fit_kwargs : dict, default `None`</span>
<span class="sd">        Additional parameters passed to the `fit` method of the regressor.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    A separate model is created for each forecasting time step. It is important to</span>
<span class="sd">    note that all models share the same parameter and hyperparameter configuration.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">regressor</span><span class="p">:</span> <span class="nb">object</span><span class="p">,</span>
        <span class="n">steps</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">lags</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">list</span><span class="p">],</span>
        <span class="n">transformer_y</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">object</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">transformer_exog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">object</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">weight_func</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">fit_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">forecaster_id</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="nb">int</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span>               <span class="o">=</span> <span class="n">regressor</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">steps</span>                   <span class="o">=</span> <span class="n">steps</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span>           <span class="o">=</span> <span class="n">transformer_y</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">transformer_exog</span>        <span class="o">=</span> <span class="n">transformer_exog</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">weight_func</span>             <span class="o">=</span> <span class="n">weight_func</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">source_code_weight_func</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_window</span>             <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index_type</span>              <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index_freq</span>              <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_range</span>          <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">included_exog</span>           <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exog_type</span>               <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exog_dtypes</span>             <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exog_col_names</span>          <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_train_col_names</span>       <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span>                  <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">creation_date</span>           <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="o">.</span><span class="n">today</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1"> %H:%M:%S&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_date</span>                <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">skforcast_version</span>       <span class="o">=</span> <span class="n">skforecast</span><span class="o">.</span><span class="n">__version__</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">python_version</span>          <span class="o">=</span> <span class="n">sys</span><span class="o">.</span><span class="n">version</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s2">&quot; &quot;</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">forecaster_id</span>           <span class="o">=</span> <span class="n">forecaster_id</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`steps` argument must be an int greater than or equal to 1. &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">steps</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`steps` argument must be greater than or equal to 1. Got </span><span class="si">{</span><span class="n">steps</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span> <span class="o">=</span> <span class="p">{</span><span class="n">step</span><span class="p">:</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">)</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">lags</span> <span class="o">=</span> <span class="n">initialize_lags</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">lags</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">weight_func</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">source_code_weight_func</span><span class="p">,</span> <span class="n">_</span> <span class="o">=</span> <span class="n">initialize_weights</span><span class="p">(</span>
            <span class="n">forecaster_name</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> 
            <span class="n">regressor</span>       <span class="o">=</span> <span class="n">regressor</span><span class="p">,</span> 
            <span class="n">weight_func</span>     <span class="o">=</span> <span class="n">weight_func</span><span class="p">,</span> 
            <span class="n">series_weights</span>  <span class="o">=</span> <span class="kc">None</span>
        <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fit_kwargs</span> <span class="o">=</span> <span class="n">check_select_fit_kwargs</span><span class="p">(</span>
                              <span class="n">regressor</span>  <span class="o">=</span> <span class="n">regressor</span><span class="p">,</span>
                              <span class="n">fit_kwargs</span> <span class="o">=</span> <span class="n">fit_kwargs</span>
                          <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">in_sample_residuals</span> <span class="o">=</span> <span class="p">{</span><span class="n">step</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span> <span class="o">=</span> <span class="kc">None</span>


    <span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span>
        <span class="bp">self</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Information displayed when a ForecasterAutoregDirect object is printed.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">,</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">):</span>
            <span class="n">name_pipe_steps</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;__&quot;</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">named_steps</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
            <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span> <span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> \
                      <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">name_pipe_steps</span><span class="p">)}</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span>

        <span class="n">info</span> <span class="o">=</span> <span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Regressor: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Lags: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Transformer for y: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Transformer for exog: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer_exog</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Weight function included: </span><span class="si">{</span><span class="kc">True</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">weight_func</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="kc">False</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Window size: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">window_size</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Maximum steps predicted: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Exogenous included: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">included_exog</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Type of exogenous variable: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">exog_type</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Exogenous variables names: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">exog_col_names</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Training range: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">training_range</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">fitted</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="kc">None</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Training index type: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">index_type</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">fitted</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="kc">None</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Training index frequency: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">index_freq</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">fitted</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="kc">None</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Regressor parameters: </span><span class="si">{</span><span class="n">params</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;fit_kwargs: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_kwargs</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Creation date: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">creation_date</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Last fit date: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_date</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Skforecast version: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">skforcast_version</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Python version: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">python_version</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
            <span class="sa">f</span><span class="s2">&quot;Forecaster id: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">forecaster_id</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="n">info</span>


    <span class="k">def</span> <span class="nf">_create_lags</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;       </span>
<span class="sd">        Transforms a 1d array into a 2d array (X) and a 1d array (y). Each row</span>
<span class="sd">        in X is associated with a value of y and it represents the lags that</span>
<span class="sd">        precede it.</span>

<span class="sd">        Notice that, the returned matrix X_data, contains the lag 1 in the first</span>
<span class="sd">        column, the lag 2 in the second column and so on.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------        </span>
<span class="sd">        y : 1d numpy ndarray</span>
<span class="sd">            Training time series.</span>

<span class="sd">        Returns </span>
<span class="sd">        -------</span>
<span class="sd">        X_data : 2d numpy ndarray, shape (samples - max(self.lags), len(self.lags))</span>
<span class="sd">            2d numpy array with the lagged values (predictors).</span>

<span class="sd">        y_data : 1d numpy ndarray, shape (samples - max(self.lags),)</span>
<span class="sd">            Values of the time series related to each row of `X_data`.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">n_splits</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">-</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="c1"># rows of y_data</span>
        <span class="k">if</span> <span class="n">n_splits</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The maximum lag (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="si">}</span><span class="s2">) must be less than the length &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;of the series minus the number of steps (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="o">-</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span><span class="si">}</span><span class="s2">).&quot;</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="n">X_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_splits</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">)),</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">lag</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">):</span>
            <span class="n">X_data</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">-</span> <span class="n">lag</span> <span class="p">:</span> <span class="o">-</span><span class="p">(</span><span class="n">lag</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)]</span> 

        <span class="n">y_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_splits</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">),</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">):</span>
            <span class="n">y_data</span><span class="p">[:,</span> <span class="n">step</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">+</span> <span class="n">step</span> <span class="p">:</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">+</span> <span class="n">step</span> <span class="o">+</span> <span class="n">n_splits</span><span class="p">]</span>

        <span class="k">return</span> <span class="n">X_data</span><span class="p">,</span> <span class="n">y_data</span>


    <span class="k">def</span> <span class="nf">create_train_X_y</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
        <span class="n">exog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Create training matrices from univariate time series and exogenous</span>
<span class="sd">        variables. The resulting matrices contain the target variable and predictors</span>
<span class="sd">        needed to train all the regressors (one per step).</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------        </span>
<span class="sd">        y : pandas Series</span>
<span class="sd">            Training time series.</span>

<span class="sd">        exog : pandas Series, pandas DataFrame, default `None`</span>
<span class="sd">            Exogenous variable/s included as predictor/s. Must have the same</span>
<span class="sd">            number of observations as `y` and their indexes must be aligned.</span>

<span class="sd">        Returns </span>
<span class="sd">        -------</span>
<span class="sd">        X_train : pandas DataFrame, shape (len(y) - self.max_lag, len(self.lags) + exog.shape[1]*steps)</span>
<span class="sd">            Pandas DataFrame with the training values (predictors) for each step.</span>

<span class="sd">        y_train : pandas DataFrame, shape (len(y) - self.max_lag, )</span>
<span class="sd">            Values (target) of the time series related to each row of `X_train` </span>
<span class="sd">            for each step.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Minimum length of `y` for training this forecaster is &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="si">}</span><span class="s2">. Got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">}</span><span class="s2">. Reduce the &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;number of predicted steps, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="si">}</span><span class="s2">, or the maximum &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;lag, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="si">}</span><span class="s2">, if no more data is available.&quot;</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="n">check_y</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">transform_series</span><span class="p">(</span>
                <span class="n">series</span>            <span class="o">=</span> <span class="n">y</span><span class="p">,</span>
                <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="p">,</span>
                <span class="n">fit</span>               <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">False</span>
            <span class="p">)</span>
        <span class="n">y_values</span><span class="p">,</span> <span class="n">y_index</span> <span class="o">=</span> <span class="n">preprocess_y</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`exog` must have same number of samples as `y`. &quot;</span>
                     <span class="sa">f</span><span class="s2">&quot;length `exog`: (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span><span class="si">}</span><span class="s2">), length `y`: (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="n">check_exog</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">,</span> <span class="n">allow_nan</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
            <span class="c1"># Need here for filter_train_X_y_for_step to work without fitting</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">included_exog</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
                <span class="n">exog</span> <span class="o">=</span> <span class="n">transform_series</span><span class="p">(</span>
                           <span class="n">series</span>            <span class="o">=</span> <span class="n">exog</span><span class="p">,</span>
                           <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_exog</span><span class="p">,</span>
                           <span class="n">fit</span>               <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                           <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">False</span>
                       <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">exog</span> <span class="o">=</span> <span class="n">transform_dataframe</span><span class="p">(</span>
                           <span class="n">df</span>                <span class="o">=</span> <span class="n">exog</span><span class="p">,</span>
                           <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_exog</span><span class="p">,</span>
                           <span class="n">fit</span>               <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                           <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">False</span>
                       <span class="p">)</span>

            <span class="n">check_exog</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">,</span> <span class="n">allow_nan</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="n">check_exog_dtypes</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">exog_dtypes</span> <span class="o">=</span> <span class="n">get_exog_dtypes</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">)</span>

            <span class="n">_</span><span class="p">,</span> <span class="n">exog_index</span> <span class="o">=</span> <span class="n">preprocess_exog</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">,</span> <span class="n">return_values</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">exog_index</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">y_index</span><span class="p">)]</span> <span class="o">==</span> <span class="n">y_index</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="p">(</span><span class="s2">&quot;Different index for `y` and `exog`. They must be equal &quot;</span>
                     <span class="s2">&quot;to ensure the correct alignment of values.&quot;</span><span class="p">)</span>      
                <span class="p">)</span>

        <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_lags</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y_values</span><span class="p">)</span>
        <span class="n">X_train_col_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;lag_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">]</span>
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                      <span class="n">data</span>    <span class="o">=</span> <span class="n">X_train</span><span class="p">,</span>
                      <span class="n">columns</span> <span class="o">=</span> <span class="n">X_train_col_names</span><span class="p">,</span>
                      <span class="n">index</span>   <span class="o">=</span> <span class="n">y_index</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span> <span class="p">]</span>
                  <span class="p">)</span>

        <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="c1"># Transform exog to match direct format</span>
            <span class="c1"># The first `self.max_lag` positions have to be removed from X_exog</span>
            <span class="c1"># since they are not in X_lags.</span>
            <span class="n">exog_to_train</span> <span class="o">=</span> <span class="n">exog_to_direct</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">)</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="p">:]</span>
            <span class="n">X_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">X_train</span><span class="p">,</span> <span class="n">exog_to_train</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">X_train_col_names</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>

        <span class="n">y_train_col_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;y_step_</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">)]</span>
        <span class="n">y_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                      <span class="n">data</span>    <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span>
                      <span class="n">index</span>   <span class="o">=</span> <span class="n">y_index</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span> <span class="p">],</span>
                      <span class="n">columns</span> <span class="o">=</span> <span class="n">y_train_col_names</span><span class="p">,</span>
                  <span class="p">)</span>

        <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span>


    <span class="k">def</span> <span class="nf">filter_train_X_y_for_step</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
        <span class="n">X_train</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
        <span class="n">y_train</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
        <span class="n">remove_suffix</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Select the columns needed to train a forecaster for a specific step.  </span>
<span class="sd">        The input matrices should be created using `create_train_X_y()`. If </span>
<span class="sd">        `remove_suffix=True` the suffix &quot;_step_i&quot; will be removed from the </span>
<span class="sd">        column names. </span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        step : int</span>
<span class="sd">            Step for which columns must be selected selected. Starts at 1.</span>

<span class="sd">        X_train : pandas DataFrame</span>
<span class="sd">            Pandas DataFrame with the training values (predictors).</span>

<span class="sd">        y_train : pandas Series</span>
<span class="sd">            Values (target) of the time series related to each row of `X_train`.</span>

<span class="sd">        remove_suffix : bool, default `False`</span>
<span class="sd">            If True, suffix &quot;_step_i&quot; is removed from the column names.</span>

<span class="sd">        Returns </span>
<span class="sd">        -------</span>
<span class="sd">        X_train_step : pandas DataFrame</span>
<span class="sd">            Pandas DataFrame with the training values (predictors) for step.</span>

<span class="sd">        y_train_step : pandas Series, shape (len(y) - self.max_lag)</span>
<span class="sd">            Values (target) of the time series related to each row of `X_train`.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">step</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">step</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid value `step`. For this forecaster, minimum value is 1 &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;and the maximum step is </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="n">step</span> <span class="o">=</span> <span class="n">step</span> <span class="o">-</span> <span class="mi">1</span> <span class="c1"># Matrices X_train and y_train start at index 0.</span>
        <span class="n">y_train_step</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">step</span><span class="p">]</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">included_exog</span><span class="p">:</span>
            <span class="n">X_train_step</span> <span class="o">=</span> <span class="n">X_train</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">idx_columns_lags</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">))</span>
            <span class="n">idx_columns_exog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">)</span> <span class="o">+</span> <span class="n">step</span><span class="p">::</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">]</span>
            <span class="n">idx_columns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">idx_columns_lags</span><span class="p">,</span> <span class="n">idx_columns_exog</span><span class="p">))</span>
            <span class="n">X_train_step</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">idx_columns</span><span class="p">]</span>

        <span class="k">if</span> <span class="n">remove_suffix</span><span class="p">:</span>
            <span class="n">X_train_step</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">col_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;_step_</span><span class="si">{</span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
                                    <span class="k">for</span> <span class="n">col_name</span> <span class="ow">in</span> <span class="n">X_train_step</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
            <span class="n">y_train_step</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">y_train_step</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;_step_</span><span class="si">{</span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

        <span class="k">return</span>  <span class="n">X_train_step</span><span class="p">,</span> <span class="n">y_train_step</span>


    <span class="k">def</span> <span class="nf">create_sample_weights</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">X_train</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="p">)</span><span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Crate weights for each observation according to the forecaster&#39;s attribute</span>
<span class="sd">        `weight_func`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        X_train : pandas DataFrame</span>
<span class="sd">           Dataframe generated with the methods `create_train_X_y` and </span>
<span class="sd">            `filter_train_X_y_for_step`, first return.</span>

<span class="sd">        Returns</span>
<span class="sd">        -------</span>
<span class="sd">        sample_weight : numpy ndarray</span>
<span class="sd">            Weights to use in `fit` method.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">sample_weight</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_func</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">sample_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_func</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;The resulting `sample_weight` cannot have NaN values.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">sample_weight</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="s2">&quot;The resulting `sample_weight` cannot have negative values.&quot;</span>
                <span class="p">)</span>
            <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="p">(</span><span class="s2">&quot;The resulting `sample_weight` cannot be normalized because &quot;</span>
                     <span class="s2">&quot;the sum of the weights is zero.&quot;</span><span class="p">)</span>
                <span class="p">)</span>

        <span class="k">return</span> <span class="n">sample_weight</span>


    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">y</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
        <span class="n">exog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Training Forecaster.</span>

<span class="sd">        Additional arguments to be passed to the `fit` method of the regressor </span>
<span class="sd">        can be added with the `fit_kwargs` argument when initializing the forecaster.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------        </span>
<span class="sd">        y : pandas Series</span>
<span class="sd">            Training time series.</span>

<span class="sd">        exog : pandas Series, pandas DataFrame, default `None`</span>
<span class="sd">            Exogenous variable/s included as predictor/s. Must have the same</span>
<span class="sd">            number of observations as `y` and their indexes must be aligned so</span>
<span class="sd">            that y[i] is regressed on exog[i].</span>

<span class="sd">        Returns </span>
<span class="sd">        -------</span>
<span class="sd">        None</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="c1"># Reset values in case the forecaster has already been fitted.</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index_type</span>          <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index_freq</span>          <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_window</span>         <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">included_exog</span>       <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exog_type</span>           <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exog_dtypes</span>         <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exog_col_names</span>      <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">X_train_col_names</span>   <span class="o">=</span> <span class="kc">None</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">in_sample_residuals</span> <span class="o">=</span> <span class="p">{</span><span class="n">step</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)}</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span>              <span class="o">=</span> <span class="kc">False</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_range</span>      <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">included_exog</span> <span class="o">=</span> <span class="kc">True</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">exog_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">exog_col_names</span> <span class="o">=</span> \
                 <span class="n">exog</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="k">else</span> <span class="n">exog</span><span class="o">.</span><span class="n">name</span>

        <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_train_X_y</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">)</span>

        <span class="c1"># Train one regressor for each step </span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span> 
            <span class="c1"># self.regressors_ and self.filter_train_X_y_for_step expect</span>
            <span class="c1"># first step to start at value 1</span>
            <span class="n">X_train_step</span><span class="p">,</span> <span class="n">y_train_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filter_train_X_y_for_step</span><span class="p">(</span>
                                             <span class="n">step</span>          <span class="o">=</span> <span class="n">step</span><span class="p">,</span>
                                             <span class="n">X_train</span>       <span class="o">=</span> <span class="n">X_train</span><span class="p">,</span>
                                             <span class="n">y_train</span>       <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span>
                                             <span class="n">remove_suffix</span> <span class="o">=</span> <span class="kc">True</span>
                                         <span class="p">)</span>
            <span class="n">sample_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_sample_weights</span><span class="p">(</span><span class="n">X_train</span><span class="o">=</span><span class="n">X_train_step</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                    <span class="n">X</span>             <span class="o">=</span> <span class="n">X_train_step</span><span class="p">,</span>
                    <span class="n">y</span>             <span class="o">=</span> <span class="n">y_train_step</span><span class="p">,</span>
                    <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">sample_weight</span><span class="p">,</span>
                    <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_kwargs</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                    <span class="n">X</span> <span class="o">=</span> <span class="n">X_train_step</span><span class="p">,</span>
                    <span class="n">y</span> <span class="o">=</span> <span class="n">y_train_step</span><span class="p">,</span>
                    <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_kwargs</span>
                <span class="p">)</span>

            <span class="n">residuals</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_train_step</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_step</span><span class="p">))</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">residuals</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1000</span><span class="p">:</span>
                <span class="c1"># Only up to 1000 residuals are stored</span>
                    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
                    <span class="n">residuals</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
                                    <span class="n">a</span>       <span class="o">=</span> <span class="n">residuals</span><span class="p">,</span> 
                                    <span class="n">size</span>    <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> 
                                    <span class="n">replace</span> <span class="o">=</span> <span class="kc">False</span>
                                <span class="p">)</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">in_sample_residuals</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">=</span> <span class="n">residuals</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">fit_date</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="o">.</span><span class="n">today</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1"> %H:%M:%S&#39;</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">training_range</span> <span class="o">=</span> <span class="n">preprocess_y</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">return_values</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">1</span><span class="p">][[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DatetimeIndex</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">index_freq</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">freqstr</span>
        <span class="k">else</span><span class="p">:</span> 
            <span class="bp">self</span><span class="o">.</span><span class="n">index_freq</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">step</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">last_window</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">:]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>


    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">last_window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">exog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Predict n steps ahead.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        steps : int, list, None, default `None`</span>
<span class="sd">            Predict n steps. The value of `steps` must be less than or equal to the </span>
<span class="sd">            value of steps defined when initializing the forecaster. Starts at 1.</span>

<span class="sd">            If `int`:</span>
<span class="sd">                Only steps within the range of 1 to int are predicted.</span>

<span class="sd">            If `list`:</span>
<span class="sd">                List of ints. Only the steps contained in the list are predicted.</span>

<span class="sd">            If `None`:</span>
<span class="sd">                As many steps are predicted as were defined at initialization.</span>

<span class="sd">        last_window : pandas Series, default `None`</span>
<span class="sd">            Series values used to create the predictors (lags) needed in the </span>
<span class="sd">            first iteration of the prediction (t + 1).</span>

<span class="sd">            If `last_window = None`, the values stored in` self.last_window` are</span>
<span class="sd">            used to calculate the initial predictors, and the predictions start</span>
<span class="sd">            right after training data.</span>

<span class="sd">        exog : pandas Series, pandas DataFrame, default `None`</span>
<span class="sd">            Exogenous variable/s included as predictor/s.</span>

<span class="sd">        Returns </span>
<span class="sd">        -------</span>
<span class="sd">        predictions : pandas Series</span>
<span class="sd">            Predicted values.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">steps</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">steps</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`steps` argument must be an int, a list of ints or `None`. &quot;</span>
                     <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">last_window</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">last_window</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">last_window</span><span class="p">)</span>

        <span class="n">check_predict_input</span><span class="p">(</span>
            <span class="n">forecaster_name</span>  <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
            <span class="n">steps</span>            <span class="o">=</span> <span class="n">steps</span><span class="p">,</span>
            <span class="n">fitted</span>           <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span><span class="p">,</span>
            <span class="n">included_exog</span>    <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">included_exog</span><span class="p">,</span>
            <span class="n">index_type</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index_type</span><span class="p">,</span>
            <span class="n">index_freq</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index_freq</span><span class="p">,</span>
            <span class="n">window_size</span>      <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span><span class="p">,</span>
            <span class="n">last_window</span>      <span class="o">=</span> <span class="n">last_window</span><span class="p">,</span>
            <span class="n">last_window_exog</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">exog</span>             <span class="o">=</span> <span class="n">exog</span><span class="p">,</span>
            <span class="n">exog_type</span>        <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog_type</span><span class="p">,</span>
            <span class="n">exog_col_names</span>   <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog_col_names</span><span class="p">,</span>
            <span class="n">interval</span>         <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">alpha</span>            <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">max_steps</span>        <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">,</span>
            <span class="n">levels</span>           <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
            <span class="n">series_col_names</span> <span class="o">=</span> <span class="kc">None</span>
        <span class="p">)</span> 

        <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
                <span class="n">exog</span> <span class="o">=</span> <span class="n">transform_dataframe</span><span class="p">(</span>
                           <span class="n">df</span>                <span class="o">=</span> <span class="n">exog</span><span class="p">,</span>
                           <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_exog</span><span class="p">,</span>
                           <span class="n">fit</span>               <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                           <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">False</span>
                       <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">exog</span> <span class="o">=</span> <span class="n">transform_series</span><span class="p">(</span>
                           <span class="n">series</span>            <span class="o">=</span> <span class="n">exog</span><span class="p">,</span>
                           <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_exog</span><span class="p">,</span>
                           <span class="n">fit</span>               <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                           <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">False</span>
                       <span class="p">)</span>
            <span class="n">check_exog_dtypes</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">)</span>
            <span class="n">exog_values</span> <span class="o">=</span> <span class="n">exog_to_direct</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="nb">max</span><span class="p">(</span><span class="n">steps</span><span class="p">),</span> <span class="p">],</span> <span class="n">steps</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">steps</span><span class="p">))</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">exog_values</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="n">last_window</span> <span class="o">=</span> <span class="n">transform_series</span><span class="p">(</span>
                          <span class="n">series</span>            <span class="o">=</span> <span class="n">last_window</span><span class="p">,</span>
                          <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="p">,</span>
                          <span class="n">fit</span>               <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                          <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">False</span>
                      <span class="p">)</span>
        <span class="n">last_window_values</span><span class="p">,</span> <span class="n">last_window_index</span> <span class="o">=</span> <span class="n">preprocess_last_window</span><span class="p">(</span>
                                                    <span class="n">last_window</span> <span class="o">=</span> <span class="n">last_window</span>
                                                <span class="p">)</span>

        <span class="n">X_lags</span> <span class="o">=</span> <span class="n">last_window_values</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Xs</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_lags</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Xs</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">X_lags</span><span class="p">,</span> <span class="n">exog_values</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">step</span><span class="o">-</span><span class="mi">1</span><span class="p">::</span><span class="nb">max</span><span class="p">(</span><span class="n">steps</span><span class="p">)]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)])</span>
                <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">steps</span>
            <span class="p">]</span>

        <span class="n">regressors</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">steps</span><span class="p">]</span>
        <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
            <span class="c1"># Suppress scikit-learn warning: &quot;X does not have valid feature names,</span>
            <span class="c1"># but NoOpTransformer was fitted with feature names&quot;.</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
            <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">regressor</span><span class="p">,</span> <span class="n">X</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">regressors</span><span class="p">,</span> <span class="n">Xs</span><span class="p">)</span>
            <span class="p">]</span>

        <span class="n">idx</span> <span class="o">=</span> <span class="n">expand_index</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">last_window_index</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">steps</span><span class="p">))</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
                          <span class="n">data</span>  <span class="o">=</span> <span class="n">predictions</span><span class="p">,</span>
                          <span class="n">index</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                          <span class="n">name</span>  <span class="o">=</span> <span class="s1">&#39;pred&#39;</span>
                      <span class="p">)</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="n">transform_series</span><span class="p">(</span>
                          <span class="n">series</span>            <span class="o">=</span> <span class="n">predictions</span><span class="p">,</span>
                          <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="p">,</span>
                          <span class="n">fit</span>               <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                          <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">True</span>
                      <span class="p">)</span>

        <span class="k">return</span> <span class="n">predictions</span>


    <span class="k">def</span> <span class="nf">predict_pandas</span><span class="p">(</span> 
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">last_window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">exog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>                                          <span class="c1"># pragma: no cover</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Equivalent to predict() but using pandas instead of numpy.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">steps</span><span class="p">))</span>

        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">steps</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)):</span>
                <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                    <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`steps` argument must be an int, a list of ints or `None`. &quot;</span>
                     <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
                <span class="p">)</span>

        <span class="k">if</span> <span class="n">last_window</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">last_window</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">last_window</span><span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">last_window_index</span> <span class="o">=</span> <span class="n">preprocess_last_window</span><span class="p">(</span>
                                   <span class="n">last_window</span>   <span class="o">=</span> <span class="n">last_window</span><span class="p">,</span>
                                   <span class="n">return_values</span> <span class="o">=</span> <span class="kc">False</span>
                               <span class="p">)</span>
        <span class="n">idx</span> <span class="o">=</span> <span class="n">expand_index</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">last_window_index</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">steps</span><span class="p">))</span>
        <span class="n">X_lags</span> <span class="o">=</span> <span class="n">last_window</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">]</span>
        <span class="n">X_lags</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;lag_</span><span class="si">{</span><span class="n">lag</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">lag</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">]</span>
        <span class="n">X_lags</span> <span class="o">=</span> <span class="n">X_lags</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>

        <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">Xs</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_lags</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">Xs</span> <span class="o">=</span> <span class="p">[</span>
                <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_lags</span><span class="p">,</span> <span class="n">exog</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">step</span><span class="o">-</span><span class="mi">1</span><span class="p">::</span><span class="nb">max</span><span class="p">(</span><span class="n">steps</span><span class="p">)]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
                <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">steps</span>
            <span class="p">]</span>

        <span class="n">regressors</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">steps</span><span class="p">]</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">regressor</span><span class="p">,</span> <span class="n">X</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">regressors</span><span class="p">,</span> <span class="n">Xs</span><span class="p">)]</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
                          <span class="n">data</span>  <span class="o">=</span> <span class="n">predictions</span><span class="p">,</span>
                          <span class="n">index</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                          <span class="n">name</span>  <span class="o">=</span> <span class="s1">&#39;pred&#39;</span><span class="p">,</span>
                      <span class="p">)</span>

        <span class="k">return</span> <span class="n">predictions</span>


    <span class="k">def</span> <span class="nf">predict_bootstrapping</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">last_window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">exog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_boot</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
        <span class="n">random_state</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
        <span class="n">in_sample_residuals</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Generate multiple forecasting predictions using a bootstrapping process. </span>
<span class="sd">        By sampling from a collection of past observed errors (the residuals),</span>
<span class="sd">        each iteration of bootstrapping generates a different set of predictions. </span>
<span class="sd">        See the Notes section for more information. </span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------   </span>
<span class="sd">        steps : int, list, None, default `None`</span>
<span class="sd">            Predict n steps. The value of `steps` must be less than or equal to the </span>
<span class="sd">            value of steps defined when initializing the forecaster. Starts at 1.</span>

<span class="sd">            If `int`:</span>
<span class="sd">                Only steps within the range of 1 to int are predicted.</span>

<span class="sd">            If `list`:</span>
<span class="sd">                List of ints. Only the steps contained in the list are predicted.</span>

<span class="sd">            If `None`:</span>
<span class="sd">                As many steps are predicted as were defined at initialization.</span>

<span class="sd">        last_window : pandas Series, default `None`</span>
<span class="sd">            Series values used to create the predictors (lags) needed in the </span>
<span class="sd">            first iteration of the prediction (t + 1).</span>

<span class="sd">            If `last_window = None`, the values stored in` self.last_window` are</span>
<span class="sd">            used to calculate the initial predictors, and the predictions start</span>
<span class="sd">            right after training data.</span>

<span class="sd">        exog : pandas Series, pandas DataFrame, default `None`</span>
<span class="sd">            Exogenous variable/s included as predictor/s.</span>

<span class="sd">        n_boot : int, default `500`</span>
<span class="sd">            Number of bootstrapping iterations used to estimate prediction</span>
<span class="sd">            intervals.</span>

<span class="sd">        random_state : int, default `123`</span>
<span class="sd">            Sets a seed to the random generator, so that boot intervals are always </span>
<span class="sd">            deterministic.</span>

<span class="sd">        in_sample_residuals : bool, default `True`</span>
<span class="sd">            If `True`, residuals from the training data are used as proxy of</span>
<span class="sd">            prediction error to create prediction intervals. If `False`, out of</span>
<span class="sd">            sample residuals are used. In the latter case, the user should have</span>
<span class="sd">            calculated and stored the residuals within the forecaster (see</span>
<span class="sd">            `set_out_sample_residuals()`).</span>

<span class="sd">        Returns </span>
<span class="sd">        -------</span>
<span class="sd">        boot_predictions : pandas DataFrame, shape (steps, n_boot)</span>
<span class="sd">            Predictions generated by bootstrapping.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        More information about prediction intervals in forecasting:</span>
<span class="sd">        https://otexts.com/fpp3/prediction-intervals.html#prediction-intervals-from-bootstrapped-residuals</span>
<span class="sd">        Forecasting: Principles and Practice (3nd ed) Rob J Hyndman and George Athanasopoulos.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="n">steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
            <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">steps</span><span class="p">))</span>

        <span class="k">if</span> <span class="n">in_sample_residuals</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_sample_residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">())):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Not `forecaster.in_sample_residuals` for steps: &quot;</span>
                     <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_sample_residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="n">residuals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_sample_residuals</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="p">(</span><span class="s2">&quot;`forecaster.out_sample_residuals` is `None`. Use &quot;</span>
                     <span class="s2">&quot;`in_sample_residuals=True` or method `set_out_sample_residuals()` &quot;</span>
                     <span class="s2">&quot;before `predict_interval()`, `predict_bootstrapping()` or &quot;</span>
                     <span class="s2">&quot;`predict_dist()`.&quot;</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">())):</span>
                    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                        <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Not `forecaster.out_sample_residuals` for steps: &quot;</span>
                         <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">. &quot;</span>
                         <span class="sa">f</span><span class="s2">&quot;Use method `set_out_sample_residuals()`.&quot;</span><span class="p">)</span>
                    <span class="p">)</span>
            <span class="n">residuals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span>

        <span class="n">check_residuals</span> <span class="o">=</span> <span class="s2">&quot;forecaster.in_sample_residuals&quot;</span> <span class="k">if</span> <span class="n">in_sample_residuals</span> <span class="k">else</span> <span class="s2">&quot;forecaster.out_sample_residuals&quot;</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">steps</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">residuals</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;forecaster residuals for step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2"> are `None`. Check </span><span class="si">{</span><span class="n">check_residuals</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
                <span class="p">)</span>
            <span class="k">elif</span> <span class="p">(</span><span class="n">residuals</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">==</span> <span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;forecaster residuals for step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2"> contains `None` values. Check </span><span class="si">{</span><span class="n">check_residuals</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
                <span class="p">)</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                          <span class="n">steps</span>       <span class="o">=</span> <span class="n">steps</span><span class="p">,</span>
                          <span class="n">last_window</span> <span class="o">=</span> <span class="n">last_window</span><span class="p">,</span>
                          <span class="n">exog</span>        <span class="o">=</span> <span class="n">exog</span> 
                      <span class="p">)</span>

        <span class="c1"># Predictions must be in the transformed scale before adding residuals</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">transform_series</span><span class="p">(</span>
                          <span class="n">series</span>            <span class="o">=</span> <span class="n">predictions</span><span class="p">,</span>
                          <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="p">,</span>
                          <span class="n">fit</span>               <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                          <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">False</span>
                      <span class="p">)</span>
        <span class="n">boot_predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">predictions</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_boot</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">boot_predictions</span><span class="o">.</span><span class="n">columns</span><span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;pred_boot_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_boot</span><span class="p">)]</span>

        <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
            <span class="n">sample_residuals</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
                                   <span class="n">a</span>       <span class="o">=</span> <span class="n">residuals</span><span class="p">[</span><span class="n">step</span><span class="p">],</span>
                                   <span class="n">size</span>    <span class="o">=</span> <span class="n">n_boot</span><span class="p">,</span>
                                   <span class="n">replace</span> <span class="o">=</span> <span class="kc">True</span>
                               <span class="p">)</span>
            <span class="n">boot_predictions</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">boot_predictions</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">sample_residuals</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="p">:</span>
            <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">boot_predictions</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
                <span class="n">boot_predictions</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">transform_series</span><span class="p">(</span>
                                            <span class="n">series</span>            <span class="o">=</span> <span class="n">boot_predictions</span><span class="p">[</span><span class="n">col</span><span class="p">],</span>
                                            <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="p">,</span>
                                            <span class="n">fit</span>               <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                            <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">True</span>
                                        <span class="p">)</span>

        <span class="k">return</span> <span class="n">boot_predictions</span>


    <span class="k">def</span> <span class="nf">predict_interval</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">last_window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">exog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">interval</span><span class="p">:</span> <span class="nb">list</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">95</span><span class="p">],</span>
        <span class="n">n_boot</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
        <span class="n">random_state</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
        <span class="n">in_sample_residuals</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Bootstrapping based prediction intervals.</span>
<span class="sd">        Both predictions and intervals are returned.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ---------- </span>
<span class="sd">        steps : int, list, None, default `None`</span>
<span class="sd">            Predict n steps. The value of `steps` must be less than or equal to the </span>
<span class="sd">            value of steps defined when initializing the forecaster. Starts at 1.</span>

<span class="sd">            If `int`:</span>
<span class="sd">                Only steps within the range of 1 to int are predicted.</span>

<span class="sd">            If `list`:</span>
<span class="sd">                List of ints. Only the steps contained in the list are predicted.</span>

<span class="sd">            If `None`:</span>
<span class="sd">                As many steps are predicted as were defined at initialization.</span>

<span class="sd">        last_window : pandas Series, default `None`</span>
<span class="sd">            Series values used to create the predictors (lags) needed in the </span>
<span class="sd">            first iteration of the prediction (t + 1).</span>

<span class="sd">            If `last_window = None`, the values stored in` self.last_window` are</span>
<span class="sd">            used to calculate the initial predictors, and the predictions start</span>
<span class="sd">            right after training data.</span>

<span class="sd">        exog : pandas Series, pandas DataFrame, default `None`</span>
<span class="sd">            Exogenous variable/s included as predictor/s.</span>

<span class="sd">        interval : list, default `[5, 95]`</span>
<span class="sd">            Confidence of the prediction interval estimated. Sequence of </span>
<span class="sd">            percentiles to compute, which must be between 0 and 100 inclusive. </span>
<span class="sd">            For example, interval of 95% should be as `interval = [2.5, 97.5]`.</span>

<span class="sd">        n_boot : int, default `500`</span>
<span class="sd">            Number of bootstrapping iterations used to estimate prediction</span>
<span class="sd">            intervals.</span>

<span class="sd">        random_state : int, default `123`</span>
<span class="sd">            Sets a seed to the random generator, so that boot intervals are always </span>
<span class="sd">            deterministic.</span>

<span class="sd">        in_sample_residuals : bool, default `True`</span>
<span class="sd">            If `True`, residuals from the training data are used as proxy of</span>
<span class="sd">            prediction error to create prediction intervals. If `False`, out of</span>
<span class="sd">            sample residuals are used. In the latter case, the user should have</span>
<span class="sd">            calculated and stored the residuals within the forecaster (see</span>
<span class="sd">            `set_out_sample_residuals()`).</span>

<span class="sd">        Returns </span>
<span class="sd">        -------</span>
<span class="sd">        predictions : pandas DataFrame</span>
<span class="sd">            Values predicted by the forecaster and their estimated interval:</span>

<span class="sd">            - pred: predictions.</span>
<span class="sd">            - lower_bound: lower bound of the interval.</span>
<span class="sd">            - upper_bound: upper bound interval of the interval.</span>

<span class="sd">        Notes</span>
<span class="sd">        -----</span>
<span class="sd">        More information about prediction intervals in forecasting:</span>
<span class="sd">        https://otexts.com/fpp2/prediction-intervals.html</span>
<span class="sd">        Forecasting: Principles and Practice (2nd ed) Rob J Hyndman and</span>
<span class="sd">        George Athanasopoulos.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">check_interval</span><span class="p">(</span><span class="n">interval</span><span class="o">=</span><span class="n">interval</span><span class="p">)</span>

        <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                          <span class="n">steps</span>       <span class="o">=</span> <span class="n">steps</span><span class="p">,</span>
                          <span class="n">last_window</span> <span class="o">=</span> <span class="n">last_window</span><span class="p">,</span>
                          <span class="n">exog</span>        <span class="o">=</span> <span class="n">exog</span>
                      <span class="p">)</span>

        <span class="n">boot_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_bootstrapping</span><span class="p">(</span>
                               <span class="n">steps</span>               <span class="o">=</span> <span class="n">steps</span><span class="p">,</span>
                               <span class="n">last_window</span>         <span class="o">=</span> <span class="n">last_window</span><span class="p">,</span>
                               <span class="n">exog</span>                <span class="o">=</span> <span class="n">exog</span><span class="p">,</span>
                               <span class="n">n_boot</span>              <span class="o">=</span> <span class="n">n_boot</span><span class="p">,</span>
                               <span class="n">random_state</span>        <span class="o">=</span> <span class="n">random_state</span><span class="p">,</span>
                               <span class="n">in_sample_residuals</span> <span class="o">=</span> <span class="n">in_sample_residuals</span>
                           <span class="p">)</span>

        <span class="n">interval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">interval</span><span class="p">)</span><span class="o">/</span><span class="mi">100</span>
        <span class="n">predictions_interval</span> <span class="o">=</span> <span class="n">boot_predictions</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="n">interval</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
        <span class="n">predictions_interval</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;lower_bound&#39;</span><span class="p">,</span> <span class="s1">&#39;upper_bound&#39;</span><span class="p">]</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">predictions</span><span class="p">,</span> <span class="n">predictions_interval</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">predictions</span>


    <span class="k">def</span> <span class="nf">predict_dist</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
        <span class="n">distribution</span><span class="p">:</span> <span class="nb">object</span><span class="p">,</span>
        <span class="n">steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">last_window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">exog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">n_boot</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
        <span class="n">random_state</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
        <span class="n">in_sample_residuals</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Fit a given probability distribution for each step. After generating </span>
<span class="sd">        multiple forecasting predictions through a bootstrapping process, each </span>
<span class="sd">        step is fitted to the given distribution.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ---------- </span>
<span class="sd">        distribution : Object</span>
<span class="sd">            A distribution object from scipy.stats.</span>

<span class="sd">        steps : int, list, None, default `None`</span>
<span class="sd">            Predict n steps. The value of `steps` must be less than or equal to the </span>
<span class="sd">            value of steps defined when initializing the forecaster. Starts at 1.</span>

<span class="sd">            If `int`:</span>
<span class="sd">                Only steps within the range of 1 to int are predicted.</span>

<span class="sd">            If `list`:</span>
<span class="sd">                List of ints. Only the steps contained in the list are predicted.</span>

<span class="sd">            If `None`:</span>
<span class="sd">                As many steps are predicted as were defined at initialization.</span>

<span class="sd">        last_window : pandas Series, default `None`</span>
<span class="sd">            Series values used to create the predictors (lags) needed in the </span>
<span class="sd">            first iteration of the prediction (t + 1).</span>

<span class="sd">            If `last_window = None`, the values stored in` self.last_window` are</span>
<span class="sd">            used to calculate the initial predictors, and the predictions start</span>
<span class="sd">            right after training data.</span>

<span class="sd">        exog : pandas Series, pandas DataFrame, default `None`</span>
<span class="sd">            Exogenous variable/s included as predictor/s.</span>

<span class="sd">        n_boot : int, default `500`</span>
<span class="sd">            Number of bootstrapping iterations used to estimate prediction</span>
<span class="sd">            intervals.</span>

<span class="sd">        random_state : int, default `123`</span>
<span class="sd">            Sets a seed to the random generator, so that boot intervals are always </span>
<span class="sd">            deterministic.</span>

<span class="sd">        in_sample_residuals : bool, default `True`</span>
<span class="sd">            If `True`, residuals from the training data are used as proxy of</span>
<span class="sd">            prediction error to create prediction intervals. If `False`, out of</span>
<span class="sd">            sample residuals are used. In the latter case, the user should have</span>
<span class="sd">            calculated and stored the residuals within the forecaster (see</span>
<span class="sd">            `set_out_sample_residuals()`).</span>

<span class="sd">        Returns </span>
<span class="sd">        -------</span>
<span class="sd">        predictions : pandas DataFrame</span>
<span class="sd">            Distribution parameters estimated for each step.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">boot_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_bootstrapping</span><span class="p">(</span>
                           <span class="n">steps</span>               <span class="o">=</span> <span class="n">steps</span><span class="p">,</span>
                           <span class="n">last_window</span>         <span class="o">=</span> <span class="n">last_window</span><span class="p">,</span>
                           <span class="n">exog</span>                <span class="o">=</span> <span class="n">exog</span><span class="p">,</span>
                           <span class="n">n_boot</span>              <span class="o">=</span> <span class="n">n_boot</span><span class="p">,</span>
                           <span class="n">random_state</span>        <span class="o">=</span> <span class="n">random_state</span><span class="p">,</span>
                           <span class="n">in_sample_residuals</span> <span class="o">=</span> <span class="n">in_sample_residuals</span>
                       <span class="p">)</span>       

        <span class="n">param_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">distribution</span><span class="o">.</span><span class="n">_pdf</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">==</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;loc&quot;</span><span class="p">,</span><span class="s2">&quot;scale&quot;</span><span class="p">]</span>
        <span class="n">param_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">distribution</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">arr</span><span class="o">=</span><span class="n">boot_samples</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                          <span class="n">data</span>    <span class="o">=</span> <span class="n">param_values</span><span class="p">,</span>
                          <span class="n">columns</span> <span class="o">=</span> <span class="n">param_names</span><span class="p">,</span>
                          <span class="n">index</span>   <span class="o">=</span> <span class="n">boot_samples</span><span class="o">.</span><span class="n">index</span>
                      <span class="p">)</span>

        <span class="k">return</span> <span class="n">predictions</span>


    <span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">params</span><span class="p">:</span> <span class="nb">dict</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set new values to the parameters of the scikit learn model stored in the</span>
<span class="sd">        forecaster. It is important to note that all models share the same </span>
<span class="sd">        configuration of parameters and hyperparameters.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        params : dict</span>
<span class="sd">            Parameters values.</span>

<span class="sd">        Returns </span>
<span class="sd">        -------</span>
<span class="sd">        self</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span> <span class="o">=</span> <span class="p">{</span><span class="n">step</span><span class="p">:</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">)</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)}</span>


    <span class="k">def</span> <span class="nf">set_fit_kwargs</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">fit_kwargs</span><span class="p">:</span> <span class="nb">dict</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set new values for the additional keyword arguments passed to the `fit` </span>
<span class="sd">        method of the regressor.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        fit_kwargs : dict</span>
<span class="sd">            Dict of the form {&quot;argument&quot;: new_value}.</span>

<span class="sd">        Returns </span>
<span class="sd">        -------</span>
<span class="sd">        None</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">fit_kwargs</span> <span class="o">=</span> <span class="n">check_select_fit_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">,</span> <span class="n">fit_kwargs</span><span class="o">=</span><span class="n">fit_kwargs</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">set_lags</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">lags</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">range</span><span class="p">]</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;      </span>
<span class="sd">        Set new value to the attribute `lags`.</span>
<span class="sd">        Attributes `max_lag` and `window_size` are also updated.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        lags : int, list, 1D np.ndarray, range</span>
<span class="sd">            Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.</span>
<span class="sd">                `int`: include lags from 1 to `lags`.</span>
<span class="sd">                `list` or `np.ndarray`: include only lags present in `lags`.</span>

<span class="sd">        Returns </span>
<span class="sd">        -------</span>
<span class="sd">        None</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">lags</span> <span class="o">=</span> <span class="n">initialize_lags</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">lags</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">)</span>


    <span class="k">def</span> <span class="nf">set_out_sample_residuals</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">residuals</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> 
        <span class="n">append</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">transform</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">random_state</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">123</span>
    <span class="p">)</span><span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set new values to the attribute `out_sample_residuals`. Out of sample</span>
<span class="sd">        residuals are meant to be calculated using observations that did not</span>
<span class="sd">        participate in the training process.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        residuals : dict</span>
<span class="sd">            Dictionary of numpy ndarrays with the residuals of each model in the</span>
<span class="sd">            form {step: residuals}. If len(residuals) &gt; 1000, only a random </span>
<span class="sd">            sample of 1000 values are stored.</span>

<span class="sd">        append : bool, default `True`</span>
<span class="sd">            If `True`, new residuals are added to the once already stored in the</span>
<span class="sd">            attribute `out_sample_residuals`. Once the limit of 1000 values is</span>
<span class="sd">            reached, no more values are appended. If False, `out_sample_residuals`</span>
<span class="sd">            is overwritten with the new residuals.</span>

<span class="sd">        transform : bool, default `True`</span>
<span class="sd">            If `True`, new residuals are transformed using self.transformer_y.</span>

<span class="sd">        random_state : int, default `123`</span>
<span class="sd">            Sets a seed to the random sampling for reproducible output.</span>

<span class="sd">        Returns </span>
<span class="sd">        -------</span>
<span class="sd">        self</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">residuals</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;`residuals` argument must be a dict of numpy ndarrays in the form &quot;</span>
                <span class="s2">&quot;`{step: residuals}`. &quot;</span> 
                <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">residuals</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">NotFittedError</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">&quot;This forecaster is not fitted yet. Call `fit` with appropriate &quot;</span>
                 <span class="s2">&quot;arguments before using `set_out_sample_residuals()`.&quot;</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span> <span class="o">=</span> <span class="p">{</span><span class="n">step</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)}</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">())):</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">                Only residuals of models (steps) </span>
<span class="s2">                </span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span><span class="si">}</span><span class="s2"> </span>
<span class="s2">                are updated.</span>
<span class="s2">                &quot;&quot;&quot;</span>
            <span class="p">)</span>

        <span class="n">residuals</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">residuals</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="n">transform</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Argument `transform` is set to `False` but forecaster was trained &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;using a transformer </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="si">}</span><span class="s2">. Ensure that the new residuals &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;are already transformed or set `transform=True`.&quot;</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="n">transform</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Residuals will be transformed using the same transformer used &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;when training the forecaster (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="si">}</span><span class="s2">). Ensure the &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;new residuals are on the same scale as the original time series.&quot;</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">residuals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
                <span class="n">residuals</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">transform_series</span><span class="p">(</span>
                                     <span class="n">series</span>            <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;residuals&#39;</span><span class="p">),</span>
                                     <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="p">,</span>
                                     <span class="n">fit</span>               <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                     <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">False</span>
                                 <span class="p">)</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">residuals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1000</span><span class="p">:</span>
                <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">append</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
                <span class="n">free_space</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1000</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="p">[</span><span class="n">key</span><span class="p">]))</span>
                <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">free_space</span><span class="p">:</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="p">[</span><span class="n">key</span><span class="p">],</span>
                                <span class="n">value</span>
                            <span class="p">))</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span>
                                <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="p">[</span><span class="n">key</span><span class="p">],</span>
                                <span class="n">value</span><span class="p">[:</span><span class="n">free_space</span><span class="p">]</span>
                            <span class="p">))</span>

            <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>


    <span class="k">def</span> <span class="nf">get_feature_importances</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">step</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Return impurity-based feature importance of the model stored in</span>
<span class="sd">        the forecaster for a specific step. Since a separate model is created for</span>
<span class="sd">        each forecast time step, it is necessary to select the model from which</span>
<span class="sd">        retrieve information. Only valid when regressor stores internally the </span>
<span class="sd">        feature importances in the attribute `feature_importances_` or `coef_`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        step : int</span>
<span class="sd">            Model from which retrieve information (a separate model is created </span>
<span class="sd">            for each forecast time step). First step is 1.</span>

<span class="sd">        Returns </span>
<span class="sd">        -------</span>
<span class="sd">        feature_importances : pandas DataFrame</span>
<span class="sd">            Feature importances associated with each predictor.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="sa">f</span><span class="s1">&#39;`step` must be an integer. Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">step</span><span class="p">)</span><span class="si">}</span><span class="s1">.&#39;</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span><span class="p">:</span>
            <span class="k">raise</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">NotFittedError</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">&quot;This forecaster is not fitted yet. Call `fit` with appropriate &quot;</span>
                 <span class="s2">&quot;arguments before using `get_feature_importances()`.&quot;</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="p">(</span><span class="n">step</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">step</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The step must have a value from 1 to the maximum number of steps &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="si">}</span><span class="s2">). Got </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="p">)</span>

        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">,</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">):</span>
            <span class="n">estimator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span><span class="p">[</span><span class="n">step</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">estimator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span><span class="p">[</span><span class="n">step</span><span class="p">]</span>

        <span class="n">idx_columns_lags</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">))</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">included_exog</span><span class="p">:</span>
            <span class="n">idx_columns_exog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train_col_names</span><span class="p">))[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">)</span> <span class="o">+</span> <span class="n">step</span><span class="o">-</span><span class="mi">1</span><span class="p">::</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">]</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">idx_columns_exog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

        <span class="n">idx_columns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">idx_columns_lags</span><span class="p">,</span> <span class="n">idx_columns_exog</span><span class="p">))</span>
        <span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train_col_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;_step_</span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> 
                         <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx_columns</span><span class="p">]</span>

        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s1">&#39;feature_importances_&#39;</span><span class="p">):</span>
            <span class="n">feature_importances</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">feature_importances_</span>
        <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s1">&#39;coef_&#39;</span><span class="p">):</span>
            <span class="n">feature_importances</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">coef_</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
                <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Impossible to access feature importances for regressor of type &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span><span class="si">}</span><span class="s2">. This method is only valid when the &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;regressor stores internally the feature importances in the &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;attribute `feature_importances_` or `coef_`.&quot;</span><span class="p">)</span>
            <span class="p">)</span>
            <span class="n">feature_importances</span> <span class="o">=</span> <span class="kc">None</span>

        <span class="k">if</span> <span class="n">feature_importances</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">feature_importances</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
                                      <span class="s1">&#39;feature&#39;</span><span class="p">:</span> <span class="n">feature_names</span><span class="p">,</span>
                                      <span class="s1">&#39;importance&#39;</span><span class="p">:</span> <span class="n">feature_importances</span>
                                  <span class="p">})</span>

        <span class="k">return</span> <span class="n">feature_importances</span>


    <span class="k">def</span> <span class="nf">get_feature_importance</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> 
        <span class="n">step</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        This method has been replaced by `get_feature_importances()`.</span>

<span class="sd">        Return impurity-based feature importance of the model stored in</span>
<span class="sd">        the forecaster for a specific step. Since a separate model is created for</span>
<span class="sd">        each forecast time step, it is necessary to select the model from which</span>
<span class="sd">        retrieve information. Only valid when regressor stores internally the </span>
<span class="sd">        feature importances in the attribute `feature_importances_` or `coef_`.</span>

<span class="sd">        Parameters</span>
<span class="sd">        ----------</span>
<span class="sd">        step : int</span>
<span class="sd">            Model from which retrieve information (a separate model is created </span>
<span class="sd">            for each forecast time step). First step is 1.</span>

<span class="sd">        Returns </span>
<span class="sd">        -------</span>
<span class="sd">        feature_importances : pandas DataFrame</span>
<span class="sd">            Feature importances associated with each predictor.</span>

<span class="sd">        &quot;&quot;&quot;</span>

        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="p">(</span><span class="s2">&quot;get_feature_importance() method has been renamed to get_feature_importances().&quot;</span>
             <span class="s2">&quot;This method will be removed in skforecast 0.9.0.&quot;</span><span class="p">)</span>
        <span class="p">)</span>

        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_feature_importances</span><span class="p">(</span><span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">)</span>
</code></pre></div>
        </details>



  <div class="doc doc-children">









  <div class="doc doc-object doc-method">



<h3 id="skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.create_sample_weights" class="doc doc-heading">
<code class="highlight language-python"><span class="n">create_sample_weights</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">X_train</span><span class="p">)</span></code>


<a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.create_sample_weights" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Crate weights for each observation according to the forecaster's attribute</p>
<p><code>weight_func</code>.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>X_train</code></td>
        <td><code>DataFrame</code></td>
        <td><p>Dataframe generated with the methods <code>create_train_X_y</code> and 
 <code>filter_train_X_y_for_step</code>, first return.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>ndarray</code></td>
      <td><p>Weights to use in <code>fit</code> method.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">create_sample_weights</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
<span class="p">)</span><span class="o">-&gt;</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Crate weights for each observation according to the forecaster&#39;s attribute</span>
<span class="sd">    `weight_func`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X_train : pandas DataFrame</span>
<span class="sd">       Dataframe generated with the methods `create_train_X_y` and </span>
<span class="sd">        `filter_train_X_y_for_step`, first return.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    sample_weight : numpy ndarray</span>
<span class="sd">        Weights to use in `fit` method.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">sample_weight</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_func</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">sample_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">weight_func</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The resulting `sample_weight` cannot have NaN values.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">any</span><span class="p">(</span><span class="n">sample_weight</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="s2">&quot;The resulting `sample_weight` cannot have negative values.&quot;</span>
            <span class="p">)</span>
        <span class="k">if</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">sample_weight</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">&quot;The resulting `sample_weight` cannot be normalized because &quot;</span>
                 <span class="s2">&quot;the sum of the weights is zero.&quot;</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="k">return</span> <span class="n">sample_weight</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.create_train_X_y" class="doc doc-heading">
<code class="highlight language-python"><span class="n">create_train_X_y</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


<a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.create_train_X_y" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Create training matrices from univariate time series and exogenous</p>
<p>variables. The resulting matrices contain the target variable and predictors
needed to train all the regressors (one per step).</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>y</code></td>
        <td><code>Series</code></td>
        <td><p>Training time series.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>exog</code></td>
        <td><code>Union[pandas.core.series.Series, pandas.core.frame.DataFrame]</code></td>
        <td><p>Exogenous variable/s included as predictor/s. Must have the same
number of observations as <code>y</code> and their indexes must be aligned.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Tuple[pandas.core.frame.DataFrame, pandas.core.frame.DataFrame]</code></td>
      <td><p>Pandas DataFrame with the training values (predictors) for each step.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">create_train_X_y</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
    <span class="n">exog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Create training matrices from univariate time series and exogenous</span>
<span class="sd">    variables. The resulting matrices contain the target variable and predictors</span>
<span class="sd">    needed to train all the regressors (one per step).</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------        </span>
<span class="sd">    y : pandas Series</span>
<span class="sd">        Training time series.</span>

<span class="sd">    exog : pandas Series, pandas DataFrame, default `None`</span>
<span class="sd">        Exogenous variable/s included as predictor/s. Must have the same</span>
<span class="sd">        number of observations as `y` and their indexes must be aligned.</span>

<span class="sd">    Returns </span>
<span class="sd">    -------</span>
<span class="sd">    X_train : pandas DataFrame, shape (len(y) - self.max_lag, len(self.lags) + exog.shape[1]*steps)</span>
<span class="sd">        Pandas DataFrame with the training values (predictors) for each step.</span>

<span class="sd">    y_train : pandas DataFrame, shape (len(y) - self.max_lag, )</span>
<span class="sd">        Values (target) of the time series related to each row of `X_train` </span>
<span class="sd">        for each step.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">&lt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Minimum length of `y` for training this forecaster is &quot;</span>
             <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="si">}</span><span class="s2">. Got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">}</span><span class="s2">. Reduce the &quot;</span>
             <span class="sa">f</span><span class="s2">&quot;number of predicted steps, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="si">}</span><span class="s2">, or the maximum &quot;</span>
             <span class="sa">f</span><span class="s2">&quot;lag, </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="si">}</span><span class="s2">, if no more data is available.&quot;</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="n">check_y</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">transform_series</span><span class="p">(</span>
            <span class="n">series</span>            <span class="o">=</span> <span class="n">y</span><span class="p">,</span>
            <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="p">,</span>
            <span class="n">fit</span>               <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
            <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="p">)</span>
    <span class="n">y_values</span><span class="p">,</span> <span class="n">y_index</span> <span class="o">=</span> <span class="n">preprocess_y</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`exog` must have same number of samples as `y`. &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;length `exog`: (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span><span class="si">}</span><span class="s2">), length `y`: (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="n">check_exog</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">,</span> <span class="n">allow_nan</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="c1"># Need here for filter_train_X_y_for_step to work without fitting</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">included_exog</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">):</span>
            <span class="n">exog</span> <span class="o">=</span> <span class="n">transform_series</span><span class="p">(</span>
                       <span class="n">series</span>            <span class="o">=</span> <span class="n">exog</span><span class="p">,</span>
                       <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_exog</span><span class="p">,</span>
                       <span class="n">fit</span>               <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                       <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">False</span>
                   <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">exog</span> <span class="o">=</span> <span class="n">transform_dataframe</span><span class="p">(</span>
                       <span class="n">df</span>                <span class="o">=</span> <span class="n">exog</span><span class="p">,</span>
                       <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_exog</span><span class="p">,</span>
                       <span class="n">fit</span>               <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
                       <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">False</span>
                   <span class="p">)</span>

        <span class="n">check_exog</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">,</span> <span class="n">allow_nan</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">check_exog_dtypes</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exog_dtypes</span> <span class="o">=</span> <span class="n">get_exog_dtypes</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">)</span>

        <span class="n">_</span><span class="p">,</span> <span class="n">exog_index</span> <span class="o">=</span> <span class="n">preprocess_exog</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">,</span> <span class="n">return_values</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="n">exog_index</span><span class="p">[:</span><span class="nb">len</span><span class="p">(</span><span class="n">y_index</span><span class="p">)]</span> <span class="o">==</span> <span class="n">y_index</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">&quot;Different index for `y` and `exog`. They must be equal &quot;</span>
                 <span class="s2">&quot;to ensure the correct alignment of values.&quot;</span><span class="p">)</span>      
            <span class="p">)</span>

    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_create_lags</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y_values</span><span class="p">)</span>
    <span class="n">X_train_col_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;lag_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">]</span>
    <span class="n">X_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                  <span class="n">data</span>    <span class="o">=</span> <span class="n">X_train</span><span class="p">,</span>
                  <span class="n">columns</span> <span class="o">=</span> <span class="n">X_train_col_names</span><span class="p">,</span>
                  <span class="n">index</span>   <span class="o">=</span> <span class="n">y_index</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span> <span class="p">]</span>
              <span class="p">)</span>

    <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="c1"># Transform exog to match direct format</span>
        <span class="c1"># The first `self.max_lag` positions have to be removed from X_exog</span>
        <span class="c1"># since they are not in X_lags.</span>
        <span class="n">exog_to_train</span> <span class="o">=</span> <span class="n">exog_to_direct</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">)</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]:,</span> <span class="p">:]</span>
        <span class="n">X_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">X_train</span><span class="p">,</span> <span class="n">exog_to_train</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">X_train_col_names</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span>

    <span class="n">y_train_col_names</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;y_step_</span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">)]</span>
    <span class="n">y_train</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                  <span class="n">data</span>    <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span>
                  <span class="n">index</span>   <span class="o">=</span> <span class="n">y_index</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">+</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">-</span><span class="mi">1</span><span class="p">):</span> <span class="p">],</span>
                  <span class="n">columns</span> <span class="o">=</span> <span class="n">y_train_col_names</span><span class="p">,</span>
              <span class="p">)</span>

    <span class="k">return</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.filter_train_X_y_for_step" class="doc doc-heading">
<code class="highlight language-python"><span class="n">filter_train_X_y_for_step</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">,</span> <span class="n">remove_suffix</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>


<a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.filter_train_X_y_for_step" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Select the columns needed to train a forecaster for a specific step.  </p>
<p>The input matrices should be created using <code>create_train_X_y()</code>. If 
<code>remove_suffix=True</code> the suffix "_step_i" will be removed from the 
column names.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>step</code></td>
        <td><code>int</code></td>
        <td><p>Step for which columns must be selected selected. Starts at 1.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>X_train</code></td>
        <td><code>DataFrame</code></td>
        <td><p>Pandas DataFrame with the training values (predictors).</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>y_train</code></td>
        <td><code>Series</code></td>
        <td><p>Values (target) of the time series related to each row of <code>X_train</code>.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>remove_suffix</code></td>
        <td><code>bool</code></td>
        <td><p>If True, suffix "_step_i" is removed from the column names.</p></td>
        <td><code>False</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Tuple[pandas.core.frame.DataFrame, pandas.core.series.Series]</code></td>
      <td><p>Pandas DataFrame with the training values (predictors) for step.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">filter_train_X_y_for_step</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">step</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">X_train</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span>
    <span class="n">y_train</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
    <span class="n">remove_suffix</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">False</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Select the columns needed to train a forecaster for a specific step.  </span>
<span class="sd">    The input matrices should be created using `create_train_X_y()`. If </span>
<span class="sd">    `remove_suffix=True` the suffix &quot;_step_i&quot; will be removed from the </span>
<span class="sd">    column names. </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    step : int</span>
<span class="sd">        Step for which columns must be selected selected. Starts at 1.</span>

<span class="sd">    X_train : pandas DataFrame</span>
<span class="sd">        Pandas DataFrame with the training values (predictors).</span>

<span class="sd">    y_train : pandas Series</span>
<span class="sd">        Values (target) of the time series related to each row of `X_train`.</span>

<span class="sd">    remove_suffix : bool, default `False`</span>
<span class="sd">        If True, suffix &quot;_step_i&quot; is removed from the column names.</span>

<span class="sd">    Returns </span>
<span class="sd">    -------</span>
<span class="sd">    X_train_step : pandas DataFrame</span>
<span class="sd">        Pandas DataFrame with the training values (predictors) for step.</span>

<span class="sd">    y_train_step : pandas Series, shape (len(y) - self.max_lag)</span>
<span class="sd">        Values (target) of the time series related to each row of `X_train`.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">step</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">step</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Invalid value `step`. For this forecaster, minimum value is 1 &quot;</span>
             <span class="sa">f</span><span class="s2">&quot;and the maximum step is </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="n">step</span> <span class="o">=</span> <span class="n">step</span> <span class="o">-</span> <span class="mi">1</span> <span class="c1"># Matrices X_train and y_train start at index 0.</span>
    <span class="n">y_train_step</span> <span class="o">=</span> <span class="n">y_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">step</span><span class="p">]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">included_exog</span><span class="p">:</span>
        <span class="n">X_train_step</span> <span class="o">=</span> <span class="n">X_train</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">idx_columns_lags</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">))</span>
        <span class="n">idx_columns_exog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">)</span> <span class="o">+</span> <span class="n">step</span><span class="p">::</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">]</span>
        <span class="n">idx_columns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">idx_columns_lags</span><span class="p">,</span> <span class="n">idx_columns_exog</span><span class="p">))</span>
        <span class="n">X_train_step</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="n">idx_columns</span><span class="p">]</span>

    <span class="k">if</span> <span class="n">remove_suffix</span><span class="p">:</span>
        <span class="n">X_train_step</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">col_name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;_step_</span><span class="si">{</span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>
                                <span class="k">for</span> <span class="n">col_name</span> <span class="ow">in</span> <span class="n">X_train_step</span><span class="o">.</span><span class="n">columns</span><span class="p">]</span>
        <span class="n">y_train_step</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">y_train_step</span><span class="o">.</span><span class="n">name</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;_step_</span><span class="si">{</span><span class="n">step</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="mi">1</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span>

    <span class="k">return</span>  <span class="n">X_train_step</span><span class="p">,</span> <span class="n">y_train_step</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.fit" class="doc doc-heading">
<code class="highlight language-python"><span class="n">fit</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


<a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.fit" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Training Forecaster.</p>
<p>Additional arguments to be passed to the <code>fit</code> method of the regressor 
can be added with the <code>fit_kwargs</code> argument when initializing the forecaster.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>y</code></td>
        <td><code>Series</code></td>
        <td><p>Training time series.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>exog</code></td>
        <td><code>Union[pandas.core.series.Series, pandas.core.frame.DataFrame]</code></td>
        <td><p>Exogenous variable/s included as predictor/s. Must have the same
number of observations as <code>y</code> and their indexes must be aligned so
that y[i] is regressed on exog[i].</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">fit</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">y</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span>
    <span class="n">exog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Training Forecaster.</span>

<span class="sd">    Additional arguments to be passed to the `fit` method of the regressor </span>
<span class="sd">    can be added with the `fit_kwargs` argument when initializing the forecaster.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------        </span>
<span class="sd">    y : pandas Series</span>
<span class="sd">        Training time series.</span>

<span class="sd">    exog : pandas Series, pandas DataFrame, default `None`</span>
<span class="sd">        Exogenous variable/s included as predictor/s. Must have the same</span>
<span class="sd">        number of observations as `y` and their indexes must be aligned so</span>
<span class="sd">        that y[i] is regressed on exog[i].</span>

<span class="sd">    Returns </span>
<span class="sd">    -------</span>
<span class="sd">    None</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Reset values in case the forecaster has already been fitted.</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">index_type</span>          <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">index_freq</span>          <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">last_window</span>         <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">included_exog</span>       <span class="o">=</span> <span class="kc">False</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">exog_type</span>           <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">exog_dtypes</span>         <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">exog_col_names</span>      <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">X_train_col_names</span>   <span class="o">=</span> <span class="kc">None</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">in_sample_residuals</span> <span class="o">=</span> <span class="p">{</span><span class="n">step</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)}</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span>              <span class="o">=</span> <span class="kc">False</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">training_range</span>      <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">included_exog</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exog_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">exog</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">exog_col_names</span> <span class="o">=</span> \
             <span class="n">exog</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="k">else</span> <span class="n">exog</span><span class="o">.</span><span class="n">name</span>

    <span class="n">X_train</span><span class="p">,</span> <span class="n">y_train</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_train_X_y</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">)</span>

    <span class="c1"># Train one regressor for each step </span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span> 
        <span class="c1"># self.regressors_ and self.filter_train_X_y_for_step expect</span>
        <span class="c1"># first step to start at value 1</span>
        <span class="n">X_train_step</span><span class="p">,</span> <span class="n">y_train_step</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">filter_train_X_y_for_step</span><span class="p">(</span>
                                         <span class="n">step</span>          <span class="o">=</span> <span class="n">step</span><span class="p">,</span>
                                         <span class="n">X_train</span>       <span class="o">=</span> <span class="n">X_train</span><span class="p">,</span>
                                         <span class="n">y_train</span>       <span class="o">=</span> <span class="n">y_train</span><span class="p">,</span>
                                         <span class="n">remove_suffix</span> <span class="o">=</span> <span class="kc">True</span>
                                     <span class="p">)</span>
        <span class="n">sample_weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">create_sample_weights</span><span class="p">(</span><span class="n">X_train</span><span class="o">=</span><span class="n">X_train_step</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">sample_weight</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                <span class="n">X</span>             <span class="o">=</span> <span class="n">X_train_step</span><span class="p">,</span>
                <span class="n">y</span>             <span class="o">=</span> <span class="n">y_train_step</span><span class="p">,</span>
                <span class="n">sample_weight</span> <span class="o">=</span> <span class="n">sample_weight</span><span class="p">,</span>
                <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_kwargs</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
                <span class="n">X</span> <span class="o">=</span> <span class="n">X_train_step</span><span class="p">,</span>
                <span class="n">y</span> <span class="o">=</span> <span class="n">y_train_step</span><span class="p">,</span>
                <span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_kwargs</span>
            <span class="p">)</span>

        <span class="n">residuals</span> <span class="o">=</span> <span class="p">(</span><span class="n">y_train_step</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_train_step</span><span class="p">))</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">residuals</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1000</span><span class="p">:</span>
            <span class="c1"># Only up to 1000 residuals are stored</span>
                <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span>
                <span class="n">residuals</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
                                <span class="n">a</span>       <span class="o">=</span> <span class="n">residuals</span><span class="p">,</span> 
                                <span class="n">size</span>    <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span> 
                                <span class="n">replace</span> <span class="o">=</span> <span class="kc">False</span>
                            <span class="p">)</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">in_sample_residuals</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">=</span> <span class="n">residuals</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">fit_date</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Timestamp</span><span class="o">.</span><span class="n">today</span><span class="p">()</span><span class="o">.</span><span class="n">strftime</span><span class="p">(</span><span class="s1">&#39;%Y-%m-</span><span class="si">%d</span><span class="s1"> %H:%M:%S&#39;</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">training_range</span> <span class="o">=</span> <span class="n">preprocess_y</span><span class="p">(</span><span class="n">y</span><span class="o">=</span><span class="n">y</span><span class="p">,</span> <span class="n">return_values</span><span class="o">=</span><span class="kc">False</span><span class="p">)[</span><span class="mi">1</span><span class="p">][[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">]]</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">index_type</span> <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DatetimeIndex</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">index_freq</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">freqstr</span>
    <span class="k">else</span><span class="p">:</span> 
        <span class="bp">self</span><span class="o">.</span><span class="n">index_freq</span> <span class="o">=</span> <span class="n">X_train</span><span class="o">.</span><span class="n">index</span><span class="o">.</span><span class="n">step</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">last_window</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">:]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.get_feature_importance" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_feature_importance</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span></code>


<a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.get_feature_importance" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>This method has been replaced by <code>get_feature_importances()</code>.</p>
<p>Return impurity-based feature importance of the model stored in
the forecaster for a specific step. Since a separate model is created for
each forecast time step, it is necessary to select the model from which
retrieve information. Only valid when regressor stores internally the 
feature importances in the attribute <code>feature_importances_</code> or <code>coef_</code>.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>step</code></td>
        <td><code>int</code></td>
        <td><p>Model from which retrieve information (a separate model is created 
for each forecast time step). First step is 1.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>Feature importances associated with each predictor.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_feature_importance</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> 
    <span class="n">step</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    This method has been replaced by `get_feature_importances()`.</span>

<span class="sd">    Return impurity-based feature importance of the model stored in</span>
<span class="sd">    the forecaster for a specific step. Since a separate model is created for</span>
<span class="sd">    each forecast time step, it is necessary to select the model from which</span>
<span class="sd">    retrieve information. Only valid when regressor stores internally the </span>
<span class="sd">    feature importances in the attribute `feature_importances_` or `coef_`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    step : int</span>
<span class="sd">        Model from which retrieve information (a separate model is created </span>
<span class="sd">        for each forecast time step). First step is 1.</span>

<span class="sd">    Returns </span>
<span class="sd">    -------</span>
<span class="sd">    feature_importances : pandas DataFrame</span>
<span class="sd">        Feature importances associated with each predictor.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="p">(</span><span class="s2">&quot;get_feature_importance() method has been renamed to get_feature_importances().&quot;</span>
         <span class="s2">&quot;This method will be removed in skforecast 0.9.0.&quot;</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_feature_importances</span><span class="p">(</span><span class="n">step</span><span class="o">=</span><span class="n">step</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.get_feature_importances" class="doc doc-heading">
<code class="highlight language-python"><span class="n">get_feature_importances</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">)</span></code>


<a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.get_feature_importances" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Return impurity-based feature importance of the model stored in</p>
<p>the forecaster for a specific step. Since a separate model is created for
each forecast time step, it is necessary to select the model from which
retrieve information. Only valid when regressor stores internally the 
feature importances in the attribute <code>feature_importances_</code> or <code>coef_</code>.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>step</code></td>
        <td><code>int</code></td>
        <td><p>Model from which retrieve information (a separate model is created 
for each forecast time step). First step is 1.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>Feature importances associated with each predictor.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">get_feature_importances</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> 
    <span class="n">step</span><span class="p">:</span> <span class="nb">int</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Return impurity-based feature importance of the model stored in</span>
<span class="sd">    the forecaster for a specific step. Since a separate model is created for</span>
<span class="sd">    each forecast time step, it is necessary to select the model from which</span>
<span class="sd">    retrieve information. Only valid when regressor stores internally the </span>
<span class="sd">    feature importances in the attribute `feature_importances_` or `coef_`.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    step : int</span>
<span class="sd">        Model from which retrieve information (a separate model is created </span>
<span class="sd">        for each forecast time step). First step is 1.</span>

<span class="sd">    Returns </span>
<span class="sd">    -------</span>
<span class="sd">    feature_importances : pandas DataFrame</span>
<span class="sd">        Feature importances associated with each predictor.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s1">&#39;`step` must be an integer. Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">step</span><span class="p">)</span><span class="si">}</span><span class="s1">.&#39;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">NotFittedError</span><span class="p">(</span>
            <span class="p">(</span><span class="s2">&quot;This forecaster is not fitted yet. Call `fit` with appropriate &quot;</span>
             <span class="s2">&quot;arguments before using `get_feature_importances()`.&quot;</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">step</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">)</span> <span class="ow">or</span> <span class="p">(</span><span class="n">step</span> <span class="o">&gt;</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">):</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The step must have a value from 1 to the maximum number of steps &quot;</span>
             <span class="sa">f</span><span class="s2">&quot;(</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="si">}</span><span class="s2">). Got </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">,</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">):</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span><span class="p">[</span><span class="n">step</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">estimator</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span><span class="p">[</span><span class="n">step</span><span class="p">]</span>

    <span class="n">idx_columns_lags</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">))</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">included_exog</span><span class="p">:</span>
        <span class="n">idx_columns_exog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train_col_names</span><span class="p">))[</span><span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">)</span> <span class="o">+</span> <span class="n">step</span><span class="o">-</span><span class="mi">1</span><span class="p">::</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">]</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">idx_columns_exog</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([],</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>

    <span class="n">idx_columns</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span><span class="n">idx_columns_lags</span><span class="p">,</span> <span class="n">idx_columns_exog</span><span class="p">))</span>
    <span class="n">feature_names</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">X_train_col_names</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;_step_</span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span> <span class="s2">&quot;&quot;</span><span class="p">)</span> 
                     <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">idx_columns</span><span class="p">]</span>

    <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s1">&#39;feature_importances_&#39;</span><span class="p">):</span>
        <span class="n">feature_importances</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">feature_importances_</span>
    <span class="k">elif</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">estimator</span><span class="p">,</span> <span class="s1">&#39;coef_&#39;</span><span class="p">):</span>
        <span class="n">feature_importances</span> <span class="o">=</span> <span class="n">estimator</span><span class="o">.</span><span class="n">coef_</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Impossible to access feature importances for regressor of type &quot;</span>
             <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">estimator</span><span class="p">)</span><span class="si">}</span><span class="s2">. This method is only valid when the &quot;</span>
             <span class="sa">f</span><span class="s2">&quot;regressor stores internally the feature importances in the &quot;</span>
             <span class="sa">f</span><span class="s2">&quot;attribute `feature_importances_` or `coef_`.&quot;</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="n">feature_importances</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="k">if</span> <span class="n">feature_importances</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">feature_importances</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
                                  <span class="s1">&#39;feature&#39;</span><span class="p">:</span> <span class="n">feature_names</span><span class="p">,</span>
                                  <span class="s1">&#39;importance&#39;</span><span class="p">:</span> <span class="n">feature_importances</span>
                              <span class="p">})</span>

    <span class="k">return</span> <span class="n">feature_importances</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict" class="doc doc-heading">
<code class="highlight language-python"><span class="n">predict</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">last_window</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


<a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Predict n steps ahead.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>steps</code></td>
        <td><code>Union[int, list]</code></td>
        <td><p>Predict n steps. The value of <code>steps</code> must be less than or equal to the 
value of steps defined when initializing the forecaster. Starts at 1.</p>
<p>If <code>int</code>:
    Only steps within the range of 1 to int are predicted.</p>
<p>If <code>list</code>:
    List of ints. Only the steps contained in the list are predicted.</p>
<p>If <code>None</code>:
    As many steps are predicted as were defined at initialization.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>last_window</code></td>
        <td><code>Optional[pandas.core.series.Series]</code></td>
        <td><p>Series values used to create the predictors (lags) needed in the 
first iteration of the prediction (t + 1).</p>
<p>If <code>last_window = None</code>, the values stored in<code>self.last_window</code> are
used to calculate the initial predictors, and the predictions start
right after training data.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>exog</code></td>
        <td><code>Union[pandas.core.series.Series, pandas.core.frame.DataFrame]</code></td>
        <td><p>Exogenous variable/s included as predictor/s.</p></td>
        <td><code>None</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Series</code></td>
      <td><p>Predicted values.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">predict</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">last_window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">exog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Predict n steps ahead.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    steps : int, list, None, default `None`</span>
<span class="sd">        Predict n steps. The value of `steps` must be less than or equal to the </span>
<span class="sd">        value of steps defined when initializing the forecaster. Starts at 1.</span>

<span class="sd">        If `int`:</span>
<span class="sd">            Only steps within the range of 1 to int are predicted.</span>

<span class="sd">        If `list`:</span>
<span class="sd">            List of ints. Only the steps contained in the list are predicted.</span>

<span class="sd">        If `None`:</span>
<span class="sd">            As many steps are predicted as were defined at initialization.</span>

<span class="sd">    last_window : pandas Series, default `None`</span>
<span class="sd">        Series values used to create the predictors (lags) needed in the </span>
<span class="sd">        first iteration of the prediction (t + 1).</span>

<span class="sd">        If `last_window = None`, the values stored in` self.last_window` are</span>
<span class="sd">        used to calculate the initial predictors, and the predictions start</span>
<span class="sd">        right after training data.</span>

<span class="sd">    exog : pandas Series, pandas DataFrame, default `None`</span>
<span class="sd">        Exogenous variable/s included as predictor/s.</span>

<span class="sd">    Returns </span>
<span class="sd">    -------</span>
<span class="sd">    predictions : pandas Series</span>
<span class="sd">        Predicted values.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">steps</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">steps</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`steps` argument must be an int, a list of ints or `None`. &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="k">if</span> <span class="n">last_window</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">last_window</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">last_window</span><span class="p">)</span>

    <span class="n">check_predict_input</span><span class="p">(</span>
        <span class="n">forecaster_name</span>  <span class="o">=</span> <span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span>
        <span class="n">steps</span>            <span class="o">=</span> <span class="n">steps</span><span class="p">,</span>
        <span class="n">fitted</span>           <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span><span class="p">,</span>
        <span class="n">included_exog</span>    <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">included_exog</span><span class="p">,</span>
        <span class="n">index_type</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index_type</span><span class="p">,</span>
        <span class="n">index_freq</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">index_freq</span><span class="p">,</span>
        <span class="n">window_size</span>      <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span><span class="p">,</span>
        <span class="n">last_window</span>      <span class="o">=</span> <span class="n">last_window</span><span class="p">,</span>
        <span class="n">last_window_exog</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">exog</span>             <span class="o">=</span> <span class="n">exog</span><span class="p">,</span>
        <span class="n">exog_type</span>        <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog_type</span><span class="p">,</span>
        <span class="n">exog_col_names</span>   <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">exog_col_names</span><span class="p">,</span>
        <span class="n">interval</span>         <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">alpha</span>            <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">max_steps</span>        <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">,</span>
        <span class="n">levels</span>           <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
        <span class="n">series_col_names</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="p">)</span> 

    <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">exog</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">):</span>
            <span class="n">exog</span> <span class="o">=</span> <span class="n">transform_dataframe</span><span class="p">(</span>
                       <span class="n">df</span>                <span class="o">=</span> <span class="n">exog</span><span class="p">,</span>
                       <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_exog</span><span class="p">,</span>
                       <span class="n">fit</span>               <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                       <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">False</span>
                   <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">exog</span> <span class="o">=</span> <span class="n">transform_series</span><span class="p">(</span>
                       <span class="n">series</span>            <span class="o">=</span> <span class="n">exog</span><span class="p">,</span>
                       <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_exog</span><span class="p">,</span>
                       <span class="n">fit</span>               <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                       <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">False</span>
                   <span class="p">)</span>
        <span class="n">check_exog_dtypes</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="p">)</span>
        <span class="n">exog_values</span> <span class="o">=</span> <span class="n">exog_to_direct</span><span class="p">(</span><span class="n">exog</span><span class="o">=</span><span class="n">exog</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="nb">max</span><span class="p">(</span><span class="n">steps</span><span class="p">),</span> <span class="p">],</span> <span class="n">steps</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">steps</span><span class="p">))</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">exog_values</span> <span class="o">=</span> <span class="kc">None</span>

    <span class="n">last_window</span> <span class="o">=</span> <span class="n">transform_series</span><span class="p">(</span>
                      <span class="n">series</span>            <span class="o">=</span> <span class="n">last_window</span><span class="p">,</span>
                      <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="p">,</span>
                      <span class="n">fit</span>               <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                      <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">False</span>
                  <span class="p">)</span>
    <span class="n">last_window_values</span><span class="p">,</span> <span class="n">last_window_index</span> <span class="o">=</span> <span class="n">preprocess_last_window</span><span class="p">(</span>
                                                <span class="n">last_window</span> <span class="o">=</span> <span class="n">last_window</span>
                                            <span class="p">)</span>

    <span class="n">X_lags</span> <span class="o">=</span> <span class="n">last_window_values</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">Xs</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_lags</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">Xs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">([</span><span class="n">X_lags</span><span class="p">,</span> <span class="n">exog_values</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="n">step</span><span class="o">-</span><span class="mi">1</span><span class="p">::</span><span class="nb">max</span><span class="p">(</span><span class="n">steps</span><span class="p">)]</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)])</span>
            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">steps</span>
        <span class="p">]</span>

    <span class="n">regressors</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">steps</span><span class="p">]</span>
    <span class="k">with</span> <span class="n">warnings</span><span class="o">.</span><span class="n">catch_warnings</span><span class="p">():</span>
        <span class="c1"># Suppress scikit-learn warning: &quot;X does not have valid feature names,</span>
        <span class="c1"># but NoOpTransformer was fitted with feature names&quot;.</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">simplefilter</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
        <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">regressor</span><span class="p">,</span> <span class="n">X</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">regressors</span><span class="p">,</span> <span class="n">Xs</span><span class="p">)</span>
        <span class="p">]</span>

    <span class="n">idx</span> <span class="o">=</span> <span class="n">expand_index</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">last_window_index</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">steps</span><span class="p">))</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
                      <span class="n">data</span>  <span class="o">=</span> <span class="n">predictions</span><span class="p">,</span>
                      <span class="n">index</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                      <span class="n">name</span>  <span class="o">=</span> <span class="s1">&#39;pred&#39;</span>
                  <span class="p">)</span>

    <span class="n">predictions</span> <span class="o">=</span> <span class="n">transform_series</span><span class="p">(</span>
                      <span class="n">series</span>            <span class="o">=</span> <span class="n">predictions</span><span class="p">,</span>
                      <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="p">,</span>
                      <span class="n">fit</span>               <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                      <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">True</span>
                  <span class="p">)</span>

    <span class="k">return</span> <span class="n">predictions</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict_bootstrapping" class="doc doc-heading">
<code class="highlight language-python"><span class="n">predict_bootstrapping</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">last_window</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_boot</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span> <span class="n">in_sample_residuals</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>


<a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict_bootstrapping" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Generate multiple forecasting predictions using a bootstrapping process. </p>
<p>By sampling from a collection of past observed errors (the residuals),
each iteration of bootstrapping generates a different set of predictions. 
See the Notes section for more information.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>steps</code></td>
        <td><code>Union[int, list]</code></td>
        <td><p>Predict n steps. The value of <code>steps</code> must be less than or equal to the 
value of steps defined when initializing the forecaster. Starts at 1.</p>
<p>If <code>int</code>:
    Only steps within the range of 1 to int are predicted.</p>
<p>If <code>list</code>:
    List of ints. Only the steps contained in the list are predicted.</p>
<p>If <code>None</code>:
    As many steps are predicted as were defined at initialization.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>last_window</code></td>
        <td><code>Optional[pandas.core.series.Series]</code></td>
        <td><p>Series values used to create the predictors (lags) needed in the 
first iteration of the prediction (t + 1).</p>
<p>If <code>last_window = None</code>, the values stored in<code>self.last_window</code> are
used to calculate the initial predictors, and the predictions start
right after training data.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>exog</code></td>
        <td><code>Union[pandas.core.series.Series, pandas.core.frame.DataFrame]</code></td>
        <td><p>Exogenous variable/s included as predictor/s.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>n_boot</code></td>
        <td><code>int</code></td>
        <td><p>Number of bootstrapping iterations used to estimate prediction
intervals.</p></td>
        <td><code>500</code></td>
      </tr>
      <tr>
        <td><code>random_state</code></td>
        <td><code>int</code></td>
        <td><p>Sets a seed to the random generator, so that boot intervals are always 
deterministic.</p></td>
        <td><code>123</code></td>
      </tr>
      <tr>
        <td><code>in_sample_residuals</code></td>
        <td><code>bool</code></td>
        <td><p>If <code>True</code>, residuals from the training data are used as proxy of
prediction error to create prediction intervals. If <code>False</code>, out of
sample residuals are used. In the latter case, the user should have
calculated and stored the residuals within the forecaster (see
<code>set_out_sample_residuals()</code>).</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>Predictions generated by bootstrapping.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_bootstrapping</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">last_window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">exog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">n_boot</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">random_state</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
    <span class="n">in_sample_residuals</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Generate multiple forecasting predictions using a bootstrapping process. </span>
<span class="sd">    By sampling from a collection of past observed errors (the residuals),</span>
<span class="sd">    each iteration of bootstrapping generates a different set of predictions. </span>
<span class="sd">    See the Notes section for more information. </span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------   </span>
<span class="sd">    steps : int, list, None, default `None`</span>
<span class="sd">        Predict n steps. The value of `steps` must be less than or equal to the </span>
<span class="sd">        value of steps defined when initializing the forecaster. Starts at 1.</span>

<span class="sd">        If `int`:</span>
<span class="sd">            Only steps within the range of 1 to int are predicted.</span>

<span class="sd">        If `list`:</span>
<span class="sd">            List of ints. Only the steps contained in the list are predicted.</span>

<span class="sd">        If `None`:</span>
<span class="sd">            As many steps are predicted as were defined at initialization.</span>

<span class="sd">    last_window : pandas Series, default `None`</span>
<span class="sd">        Series values used to create the predictors (lags) needed in the </span>
<span class="sd">        first iteration of the prediction (t + 1).</span>

<span class="sd">        If `last_window = None`, the values stored in` self.last_window` are</span>
<span class="sd">        used to calculate the initial predictors, and the predictions start</span>
<span class="sd">        right after training data.</span>

<span class="sd">    exog : pandas Series, pandas DataFrame, default `None`</span>
<span class="sd">        Exogenous variable/s included as predictor/s.</span>

<span class="sd">    n_boot : int, default `500`</span>
<span class="sd">        Number of bootstrapping iterations used to estimate prediction</span>
<span class="sd">        intervals.</span>

<span class="sd">    random_state : int, default `123`</span>
<span class="sd">        Sets a seed to the random generator, so that boot intervals are always </span>
<span class="sd">        deterministic.</span>

<span class="sd">    in_sample_residuals : bool, default `True`</span>
<span class="sd">        If `True`, residuals from the training data are used as proxy of</span>
<span class="sd">        prediction error to create prediction intervals. If `False`, out of</span>
<span class="sd">        sample residuals are used. In the latter case, the user should have</span>
<span class="sd">        calculated and stored the residuals within the forecaster (see</span>
<span class="sd">        `set_out_sample_residuals()`).</span>

<span class="sd">    Returns </span>
<span class="sd">    -------</span>
<span class="sd">    boot_predictions : pandas DataFrame, shape (steps, n_boot)</span>
<span class="sd">        Predictions generated by bootstrapping.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    More information about prediction intervals in forecasting:</span>
<span class="sd">    https://otexts.com/fpp3/prediction-intervals.html#prediction-intervals-from-bootstrapped-residuals</span>
<span class="sd">    Forecasting: Principles and Practice (3nd ed) Rob J Hyndman and George Athanasopoulos.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">steps</span><span class="p">))</span>

    <span class="k">if</span> <span class="n">in_sample_residuals</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_sample_residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">())):</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Not `forecaster.in_sample_residuals` for steps: &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">in_sample_residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="n">residuals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">in_sample_residuals</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="s2">&quot;`forecaster.out_sample_residuals` is `None`. Use &quot;</span>
                 <span class="s2">&quot;`in_sample_residuals=True` or method `set_out_sample_residuals()` &quot;</span>
                 <span class="s2">&quot;before `predict_interval()`, `predict_bootstrapping()` or &quot;</span>
                 <span class="s2">&quot;`predict_dist()`.&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">())):</span>
                <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                    <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Not `forecaster.out_sample_residuals` for steps: &quot;</span>
                     <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="si">}</span><span class="s2">. &quot;</span>
                     <span class="sa">f</span><span class="s2">&quot;Use method `set_out_sample_residuals()`.&quot;</span><span class="p">)</span>
                <span class="p">)</span>
        <span class="n">residuals</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span>

    <span class="n">check_residuals</span> <span class="o">=</span> <span class="s2">&quot;forecaster.in_sample_residuals&quot;</span> <span class="k">if</span> <span class="n">in_sample_residuals</span> <span class="k">else</span> <span class="s2">&quot;forecaster.out_sample_residuals&quot;</span>
    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">steps</span><span class="p">:</span>
        <span class="k">if</span> <span class="n">residuals</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;forecaster residuals for step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2"> are `None`. Check </span><span class="si">{</span><span class="n">check_residuals</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="p">)</span>
        <span class="k">elif</span> <span class="p">(</span><span class="n">residuals</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">==</span> <span class="kc">None</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
                <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;forecaster residuals for step </span><span class="si">{</span><span class="n">step</span><span class="si">}</span><span class="s2"> contains `None` values. Check </span><span class="si">{</span><span class="n">check_residuals</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                      <span class="n">steps</span>       <span class="o">=</span> <span class="n">steps</span><span class="p">,</span>
                      <span class="n">last_window</span> <span class="o">=</span> <span class="n">last_window</span><span class="p">,</span>
                      <span class="n">exog</span>        <span class="o">=</span> <span class="n">exog</span> 
                  <span class="p">)</span>

    <span class="c1"># Predictions must be in the transformed scale before adding residuals</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">transform_series</span><span class="p">(</span>
                      <span class="n">series</span>            <span class="o">=</span> <span class="n">predictions</span><span class="p">,</span>
                      <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="p">,</span>
                      <span class="n">fit</span>               <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                      <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">False</span>
                  <span class="p">)</span>
    <span class="n">boot_predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">predictions</span><span class="p">]</span> <span class="o">*</span> <span class="n">n_boot</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">boot_predictions</span><span class="o">.</span><span class="n">columns</span><span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;pred_boot_</span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n_boot</span><span class="p">)]</span>

    <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">steps</span><span class="p">):</span>
        <span class="n">sample_residuals</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span>
                               <span class="n">a</span>       <span class="o">=</span> <span class="n">residuals</span><span class="p">[</span><span class="n">step</span><span class="p">],</span>
                               <span class="n">size</span>    <span class="o">=</span> <span class="n">n_boot</span><span class="p">,</span>
                               <span class="n">replace</span> <span class="o">=</span> <span class="kc">True</span>
                           <span class="p">)</span>
        <span class="n">boot_predictions</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">=</span> <span class="n">boot_predictions</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="p">:]</span> <span class="o">+</span> <span class="n">sample_residuals</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">col</span> <span class="ow">in</span> <span class="n">boot_predictions</span><span class="o">.</span><span class="n">columns</span><span class="p">:</span>
            <span class="n">boot_predictions</span><span class="p">[</span><span class="n">col</span><span class="p">]</span> <span class="o">=</span> <span class="n">transform_series</span><span class="p">(</span>
                                        <span class="n">series</span>            <span class="o">=</span> <span class="n">boot_predictions</span><span class="p">[</span><span class="n">col</span><span class="p">],</span>
                                        <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="p">,</span>
                                        <span class="n">fit</span>               <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                        <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">True</span>
                                    <span class="p">)</span>

    <span class="k">return</span> <span class="n">boot_predictions</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict_dist" class="doc doc-heading">
<code class="highlight language-python"><span class="n">predict_dist</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">distribution</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">last_window</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">n_boot</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span> <span class="n">in_sample_residuals</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>


<a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict_dist" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Fit a given probability distribution for each step. After generating </p>
<p>multiple forecasting predictions through a bootstrapping process, each 
step is fitted to the given distribution.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>distribution</code></td>
        <td><code>object</code></td>
        <td><p>A distribution object from scipy.stats.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>steps</code></td>
        <td><code>Union[int, list]</code></td>
        <td><p>Predict n steps. The value of <code>steps</code> must be less than or equal to the 
value of steps defined when initializing the forecaster. Starts at 1.</p>
<p>If <code>int</code>:
    Only steps within the range of 1 to int are predicted.</p>
<p>If <code>list</code>:
    List of ints. Only the steps contained in the list are predicted.</p>
<p>If <code>None</code>:
    As many steps are predicted as were defined at initialization.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>last_window</code></td>
        <td><code>Optional[pandas.core.series.Series]</code></td>
        <td><p>Series values used to create the predictors (lags) needed in the 
first iteration of the prediction (t + 1).</p>
<p>If <code>last_window = None</code>, the values stored in<code>self.last_window</code> are
used to calculate the initial predictors, and the predictions start
right after training data.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>exog</code></td>
        <td><code>Union[pandas.core.series.Series, pandas.core.frame.DataFrame]</code></td>
        <td><p>Exogenous variable/s included as predictor/s.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>n_boot</code></td>
        <td><code>int</code></td>
        <td><p>Number of bootstrapping iterations used to estimate prediction
intervals.</p></td>
        <td><code>500</code></td>
      </tr>
      <tr>
        <td><code>random_state</code></td>
        <td><code>int</code></td>
        <td><p>Sets a seed to the random generator, so that boot intervals are always 
deterministic.</p></td>
        <td><code>123</code></td>
      </tr>
      <tr>
        <td><code>in_sample_residuals</code></td>
        <td><code>bool</code></td>
        <td><p>If <code>True</code>, residuals from the training data are used as proxy of
prediction error to create prediction intervals. If <code>False</code>, out of
sample residuals are used. In the latter case, the user should have
calculated and stored the residuals within the forecaster (see
<code>set_out_sample_residuals()</code>).</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>Distribution parameters estimated for each step.</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_dist</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">distribution</span><span class="p">:</span> <span class="nb">object</span><span class="p">,</span>
    <span class="n">steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">last_window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">exog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">n_boot</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">random_state</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
    <span class="n">in_sample_residuals</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Fit a given probability distribution for each step. After generating </span>
<span class="sd">    multiple forecasting predictions through a bootstrapping process, each </span>
<span class="sd">    step is fitted to the given distribution.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ---------- </span>
<span class="sd">    distribution : Object</span>
<span class="sd">        A distribution object from scipy.stats.</span>

<span class="sd">    steps : int, list, None, default `None`</span>
<span class="sd">        Predict n steps. The value of `steps` must be less than or equal to the </span>
<span class="sd">        value of steps defined when initializing the forecaster. Starts at 1.</span>

<span class="sd">        If `int`:</span>
<span class="sd">            Only steps within the range of 1 to int are predicted.</span>

<span class="sd">        If `list`:</span>
<span class="sd">            List of ints. Only the steps contained in the list are predicted.</span>

<span class="sd">        If `None`:</span>
<span class="sd">            As many steps are predicted as were defined at initialization.</span>

<span class="sd">    last_window : pandas Series, default `None`</span>
<span class="sd">        Series values used to create the predictors (lags) needed in the </span>
<span class="sd">        first iteration of the prediction (t + 1).</span>

<span class="sd">        If `last_window = None`, the values stored in` self.last_window` are</span>
<span class="sd">        used to calculate the initial predictors, and the predictions start</span>
<span class="sd">        right after training data.</span>

<span class="sd">    exog : pandas Series, pandas DataFrame, default `None`</span>
<span class="sd">        Exogenous variable/s included as predictor/s.</span>

<span class="sd">    n_boot : int, default `500`</span>
<span class="sd">        Number of bootstrapping iterations used to estimate prediction</span>
<span class="sd">        intervals.</span>

<span class="sd">    random_state : int, default `123`</span>
<span class="sd">        Sets a seed to the random generator, so that boot intervals are always </span>
<span class="sd">        deterministic.</span>

<span class="sd">    in_sample_residuals : bool, default `True`</span>
<span class="sd">        If `True`, residuals from the training data are used as proxy of</span>
<span class="sd">        prediction error to create prediction intervals. If `False`, out of</span>
<span class="sd">        sample residuals are used. In the latter case, the user should have</span>
<span class="sd">        calculated and stored the residuals within the forecaster (see</span>
<span class="sd">        `set_out_sample_residuals()`).</span>

<span class="sd">    Returns </span>
<span class="sd">    -------</span>
<span class="sd">    predictions : pandas DataFrame</span>
<span class="sd">        Distribution parameters estimated for each step.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">boot_samples</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_bootstrapping</span><span class="p">(</span>
                       <span class="n">steps</span>               <span class="o">=</span> <span class="n">steps</span><span class="p">,</span>
                       <span class="n">last_window</span>         <span class="o">=</span> <span class="n">last_window</span><span class="p">,</span>
                       <span class="n">exog</span>                <span class="o">=</span> <span class="n">exog</span><span class="p">,</span>
                       <span class="n">n_boot</span>              <span class="o">=</span> <span class="n">n_boot</span><span class="p">,</span>
                       <span class="n">random_state</span>        <span class="o">=</span> <span class="n">random_state</span><span class="p">,</span>
                       <span class="n">in_sample_residuals</span> <span class="o">=</span> <span class="n">in_sample_residuals</span>
                   <span class="p">)</span>       

    <span class="n">param_names</span> <span class="o">=</span> <span class="p">[</span><span class="n">p</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">distribution</span><span class="o">.</span><span class="n">_pdf</span><span class="p">)</span><span class="o">.</span><span class="n">parameters</span> <span class="k">if</span> <span class="ow">not</span> <span class="n">p</span><span class="o">==</span><span class="s1">&#39;x&#39;</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="s2">&quot;loc&quot;</span><span class="p">,</span><span class="s2">&quot;scale&quot;</span><span class="p">]</span>
    <span class="n">param_values</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">apply_along_axis</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">:</span> <span class="n">distribution</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">arr</span><span class="o">=</span><span class="n">boot_samples</span><span class="p">)</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span>
                      <span class="n">data</span>    <span class="o">=</span> <span class="n">param_values</span><span class="p">,</span>
                      <span class="n">columns</span> <span class="o">=</span> <span class="n">param_names</span><span class="p">,</span>
                      <span class="n">index</span>   <span class="o">=</span> <span class="n">boot_samples</span><span class="o">.</span><span class="n">index</span>
                  <span class="p">)</span>

    <span class="k">return</span> <span class="n">predictions</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict_interval" class="doc doc-heading">
<code class="highlight language-python"><span class="n">predict_interval</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">last_window</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">interval</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">95</span><span class="p">],</span> <span class="n">n_boot</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span> <span class="n">in_sample_residuals</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span></code>


<a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict_interval" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Bootstrapping based prediction intervals.</p>
<p>Both predictions and intervals are returned.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>steps</code></td>
        <td><code>Union[int, list]</code></td>
        <td><p>Predict n steps. The value of <code>steps</code> must be less than or equal to the 
value of steps defined when initializing the forecaster. Starts at 1.</p>
<p>If <code>int</code>:
    Only steps within the range of 1 to int are predicted.</p>
<p>If <code>list</code>:
    List of ints. Only the steps contained in the list are predicted.</p>
<p>If <code>None</code>:
    As many steps are predicted as were defined at initialization.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>last_window</code></td>
        <td><code>Optional[pandas.core.series.Series]</code></td>
        <td><p>Series values used to create the predictors (lags) needed in the 
first iteration of the prediction (t + 1).</p>
<p>If <code>last_window = None</code>, the values stored in<code>self.last_window</code> are
used to calculate the initial predictors, and the predictions start
right after training data.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>exog</code></td>
        <td><code>Union[pandas.core.series.Series, pandas.core.frame.DataFrame]</code></td>
        <td><p>Exogenous variable/s included as predictor/s.</p></td>
        <td><code>None</code></td>
      </tr>
      <tr>
        <td><code>interval</code></td>
        <td><code>list</code></td>
        <td><p>Confidence of the prediction interval estimated. Sequence of 
percentiles to compute, which must be between 0 and 100 inclusive. 
For example, interval of 95% should be as <code>interval = [2.5, 97.5]</code>.</p></td>
        <td><code>[5, 95]</code></td>
      </tr>
      <tr>
        <td><code>n_boot</code></td>
        <td><code>int</code></td>
        <td><p>Number of bootstrapping iterations used to estimate prediction
intervals.</p></td>
        <td><code>500</code></td>
      </tr>
      <tr>
        <td><code>random_state</code></td>
        <td><code>int</code></td>
        <td><p>Sets a seed to the random generator, so that boot intervals are always 
deterministic.</p></td>
        <td><code>123</code></td>
      </tr>
      <tr>
        <td><code>in_sample_residuals</code></td>
        <td><code>bool</code></td>
        <td><p>If <code>True</code>, residuals from the training data are used as proxy of
prediction error to create prediction intervals. If <code>False</code>, out of
sample residuals are used. In the latter case, the user should have
calculated and stored the residuals within the forecaster (see
<code>set_out_sample_residuals()</code>).</p></td>
        <td><code>True</code></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>DataFrame</code></td>
      <td><p>Values predicted by the forecaster and their estimated interval:</p>
<ul>
<li>pred: predictions.</li>
<li>lower_bound: lower bound of the interval.</li>
<li>upper_bound: upper bound interval of the interval.</li>
</ul></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_interval</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">last_window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">exog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">interval</span><span class="p">:</span> <span class="nb">list</span><span class="o">=</span><span class="p">[</span><span class="mi">5</span><span class="p">,</span> <span class="mi">95</span><span class="p">],</span>
    <span class="n">n_boot</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">500</span><span class="p">,</span>
    <span class="n">random_state</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
    <span class="n">in_sample_residuals</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Bootstrapping based prediction intervals.</span>
<span class="sd">    Both predictions and intervals are returned.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ---------- </span>
<span class="sd">    steps : int, list, None, default `None`</span>
<span class="sd">        Predict n steps. The value of `steps` must be less than or equal to the </span>
<span class="sd">        value of steps defined when initializing the forecaster. Starts at 1.</span>

<span class="sd">        If `int`:</span>
<span class="sd">            Only steps within the range of 1 to int are predicted.</span>

<span class="sd">        If `list`:</span>
<span class="sd">            List of ints. Only the steps contained in the list are predicted.</span>

<span class="sd">        If `None`:</span>
<span class="sd">            As many steps are predicted as were defined at initialization.</span>

<span class="sd">    last_window : pandas Series, default `None`</span>
<span class="sd">        Series values used to create the predictors (lags) needed in the </span>
<span class="sd">        first iteration of the prediction (t + 1).</span>

<span class="sd">        If `last_window = None`, the values stored in` self.last_window` are</span>
<span class="sd">        used to calculate the initial predictors, and the predictions start</span>
<span class="sd">        right after training data.</span>

<span class="sd">    exog : pandas Series, pandas DataFrame, default `None`</span>
<span class="sd">        Exogenous variable/s included as predictor/s.</span>

<span class="sd">    interval : list, default `[5, 95]`</span>
<span class="sd">        Confidence of the prediction interval estimated. Sequence of </span>
<span class="sd">        percentiles to compute, which must be between 0 and 100 inclusive. </span>
<span class="sd">        For example, interval of 95% should be as `interval = [2.5, 97.5]`.</span>

<span class="sd">    n_boot : int, default `500`</span>
<span class="sd">        Number of bootstrapping iterations used to estimate prediction</span>
<span class="sd">        intervals.</span>

<span class="sd">    random_state : int, default `123`</span>
<span class="sd">        Sets a seed to the random generator, so that boot intervals are always </span>
<span class="sd">        deterministic.</span>

<span class="sd">    in_sample_residuals : bool, default `True`</span>
<span class="sd">        If `True`, residuals from the training data are used as proxy of</span>
<span class="sd">        prediction error to create prediction intervals. If `False`, out of</span>
<span class="sd">        sample residuals are used. In the latter case, the user should have</span>
<span class="sd">        calculated and stored the residuals within the forecaster (see</span>
<span class="sd">        `set_out_sample_residuals()`).</span>

<span class="sd">    Returns </span>
<span class="sd">    -------</span>
<span class="sd">    predictions : pandas DataFrame</span>
<span class="sd">        Values predicted by the forecaster and their estimated interval:</span>

<span class="sd">        - pred: predictions.</span>
<span class="sd">        - lower_bound: lower bound of the interval.</span>
<span class="sd">        - upper_bound: upper bound interval of the interval.</span>

<span class="sd">    Notes</span>
<span class="sd">    -----</span>
<span class="sd">    More information about prediction intervals in forecasting:</span>
<span class="sd">    https://otexts.com/fpp2/prediction-intervals.html</span>
<span class="sd">    Forecasting: Principles and Practice (2nd ed) Rob J Hyndman and</span>
<span class="sd">    George Athanasopoulos.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">check_interval</span><span class="p">(</span><span class="n">interval</span><span class="o">=</span><span class="n">interval</span><span class="p">)</span>

    <span class="n">predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span>
                      <span class="n">steps</span>       <span class="o">=</span> <span class="n">steps</span><span class="p">,</span>
                      <span class="n">last_window</span> <span class="o">=</span> <span class="n">last_window</span><span class="p">,</span>
                      <span class="n">exog</span>        <span class="o">=</span> <span class="n">exog</span>
                  <span class="p">)</span>

    <span class="n">boot_predictions</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">predict_bootstrapping</span><span class="p">(</span>
                           <span class="n">steps</span>               <span class="o">=</span> <span class="n">steps</span><span class="p">,</span>
                           <span class="n">last_window</span>         <span class="o">=</span> <span class="n">last_window</span><span class="p">,</span>
                           <span class="n">exog</span>                <span class="o">=</span> <span class="n">exog</span><span class="p">,</span>
                           <span class="n">n_boot</span>              <span class="o">=</span> <span class="n">n_boot</span><span class="p">,</span>
                           <span class="n">random_state</span>        <span class="o">=</span> <span class="n">random_state</span><span class="p">,</span>
                           <span class="n">in_sample_residuals</span> <span class="o">=</span> <span class="n">in_sample_residuals</span>
                       <span class="p">)</span>

    <span class="n">interval</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">interval</span><span class="p">)</span><span class="o">/</span><span class="mi">100</span>
    <span class="n">predictions_interval</span> <span class="o">=</span> <span class="n">boot_predictions</span><span class="o">.</span><span class="n">quantile</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="n">interval</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">transpose</span><span class="p">()</span>
    <span class="n">predictions_interval</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;lower_bound&#39;</span><span class="p">,</span> <span class="s1">&#39;upper_bound&#39;</span><span class="p">]</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">((</span><span class="n">predictions</span><span class="p">,</span> <span class="n">predictions_interval</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">predictions</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict_pandas" class="doc doc-heading">
<code class="highlight language-python"><span class="n">predict_pandas</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">last_window</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">exog</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>


<a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.predict_pandas" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Equivalent to predict() but using pandas instead of numpy.</p>

        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">predict_pandas</span><span class="p">(</span> 
    <span class="bp">self</span><span class="p">,</span>
    <span class="n">steps</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">last_window</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">]</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
    <span class="n">exog</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">]]</span><span class="o">=</span><span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">:</span>                                          <span class="c1"># pragma: no cover</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Equivalent to predict() but using pandas instead of numpy.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
        <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="n">steps</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">steps</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">elif</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">steps</span><span class="p">,</span> <span class="nb">list</span><span class="p">):</span>
        <span class="n">steps</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">steps</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">steps</span><span class="p">:</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="p">(</span><span class="nb">int</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)):</span>
            <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
                <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`steps` argument must be an int, a list of ints or `None`. &quot;</span>
                 <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span><span class="p">)</span>
            <span class="p">)</span>

    <span class="k">if</span> <span class="n">last_window</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">last_window</span> <span class="o">=</span> <span class="n">copy</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">last_window</span><span class="p">)</span>

    <span class="n">_</span><span class="p">,</span> <span class="n">last_window_index</span> <span class="o">=</span> <span class="n">preprocess_last_window</span><span class="p">(</span>
                               <span class="n">last_window</span>   <span class="o">=</span> <span class="n">last_window</span><span class="p">,</span>
                               <span class="n">return_values</span> <span class="o">=</span> <span class="kc">False</span>
                           <span class="p">)</span>
    <span class="n">idx</span> <span class="o">=</span> <span class="n">expand_index</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">last_window_index</span><span class="p">,</span> <span class="n">steps</span><span class="o">=</span><span class="nb">max</span><span class="p">(</span><span class="n">steps</span><span class="p">))</span>
    <span class="n">X_lags</span> <span class="o">=</span> <span class="n">last_window</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="o">-</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">]</span>
    <span class="n">X_lags</span><span class="o">.</span><span class="n">index</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;lag_</span><span class="si">{</span><span class="n">lag</span><span class="si">}</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">lag</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">]</span>
    <span class="n">X_lags</span> <span class="o">=</span> <span class="n">X_lags</span><span class="o">.</span><span class="n">to_frame</span><span class="p">()</span><span class="o">.</span><span class="n">T</span>

    <span class="k">if</span> <span class="n">exog</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">Xs</span> <span class="o">=</span> <span class="p">[</span><span class="n">X_lags</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">Xs</span> <span class="o">=</span> <span class="p">[</span>
            <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">X_lags</span><span class="p">,</span> <span class="n">exog</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="n">step</span><span class="o">-</span><span class="mi">1</span><span class="p">::</span><span class="nb">max</span><span class="p">(</span><span class="n">steps</span><span class="p">)]],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">steps</span>
        <span class="p">]</span>

    <span class="n">regressors</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="n">steps</span><span class="p">]</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="p">[</span><span class="n">regressor</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span> <span class="k">for</span> <span class="n">regressor</span><span class="p">,</span> <span class="n">X</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">regressors</span><span class="p">,</span> <span class="n">Xs</span><span class="p">)]</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span>
                      <span class="n">data</span>  <span class="o">=</span> <span class="n">predictions</span><span class="p">,</span>
                      <span class="n">index</span> <span class="o">=</span> <span class="n">idx</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">steps</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                      <span class="n">name</span>  <span class="o">=</span> <span class="s1">&#39;pred&#39;</span><span class="p">,</span>
                  <span class="p">)</span>

    <span class="k">return</span> <span class="n">predictions</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.set_fit_kwargs" class="doc doc-heading">
<code class="highlight language-python"><span class="n">set_fit_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">fit_kwargs</span><span class="p">)</span></code>


<a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.set_fit_kwargs" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Set new values for the additional keyword arguments passed to the <code>fit</code> </p>
<p>method of the regressor.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>fit_kwargs</code></td>
        <td><code>dict</code></td>
        <td><p>Dict of the form {"argument": new_value}.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">set_fit_kwargs</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> 
    <span class="n">fit_kwargs</span><span class="p">:</span> <span class="nb">dict</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set new values for the additional keyword arguments passed to the `fit` </span>
<span class="sd">    method of the regressor.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    fit_kwargs : dict</span>
<span class="sd">        Dict of the form {&quot;argument&quot;: new_value}.</span>

<span class="sd">    Returns </span>
<span class="sd">    -------</span>
<span class="sd">    None</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">fit_kwargs</span> <span class="o">=</span> <span class="n">check_select_fit_kwargs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">,</span> <span class="n">fit_kwargs</span><span class="o">=</span><span class="n">fit_kwargs</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.set_lags" class="doc doc-heading">
<code class="highlight language-python"><span class="n">set_lags</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lags</span><span class="p">)</span></code>


<a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.set_lags" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Set new value to the attribute <code>lags</code>.</p>
<p>Attributes <code>max_lag</code> and <code>window_size</code> are also updated.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>lags</code></td>
        <td><code>Union[int, list, numpy.ndarray, range]</code></td>
        <td><p>Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.
    <code>int</code>: include lags from 1 to <code>lags</code>.
    <code>list</code> or <code>np.ndarray</code>: include only lags present in <code>lags</code>.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">set_lags</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> 
    <span class="n">lags</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">list</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="nb">range</span><span class="p">]</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;      </span>
<span class="sd">    Set new value to the attribute `lags`.</span>
<span class="sd">    Attributes `max_lag` and `window_size` are also updated.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    lags : int, list, 1D np.ndarray, range</span>
<span class="sd">        Lags used as predictors. Index starts at 1, so lag 1 is equal to t-1.</span>
<span class="sd">            `int`: include lags from 1 to `lags`.</span>
<span class="sd">            `list` or `np.ndarray`: include only lags present in `lags`.</span>

<span class="sd">    Returns </span>
<span class="sd">    -------</span>
<span class="sd">    None</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">lags</span> <span class="o">=</span> <span class="n">initialize_lags</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">,</span> <span class="n">lags</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">window_size</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">)</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.set_out_sample_residuals" class="doc doc-heading">
<code class="highlight language-python"><span class="n">set_out_sample_residuals</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">residuals</span><span class="p">,</span> <span class="n">append</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">transform</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">123</span><span class="p">)</span></code>


<a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.set_out_sample_residuals" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Set new values to the attribute <code>out_sample_residuals</code>. Out of sample</p>
<p>residuals are meant to be calculated using observations that did not
participate in the training process.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>residuals</code></td>
        <td><code>dict</code></td>
        <td><p>Dictionary of numpy ndarrays with the residuals of each model in the
form {step: residuals}. If len(residuals) &gt; 1000, only a random 
sample of 1000 values are stored.</p></td>
        <td><em>required</em></td>
      </tr>
      <tr>
        <td><code>append</code></td>
        <td><code>bool</code></td>
        <td><p>If <code>True</code>, new residuals are added to the once already stored in the
attribute <code>out_sample_residuals</code>. Once the limit of 1000 values is
reached, no more values are appended. If False, <code>out_sample_residuals</code>
is overwritten with the new residuals.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>transform</code></td>
        <td><code>bool</code></td>
        <td><p>If <code>True</code>, new residuals are transformed using self.transformer_y.</p></td>
        <td><code>True</code></td>
      </tr>
      <tr>
        <td><code>random_state</code></td>
        <td><code>int</code></td>
        <td><p>Sets a seed to the random sampling for reproducible output.</p></td>
        <td><code>123</code></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">set_out_sample_residuals</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> 
    <span class="n">residuals</span><span class="p">:</span> <span class="nb">dict</span><span class="p">,</span> 
    <span class="n">append</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">transform</span><span class="p">:</span> <span class="nb">bool</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
    <span class="n">random_state</span><span class="p">:</span> <span class="nb">int</span><span class="o">=</span><span class="mi">123</span>
<span class="p">)</span><span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set new values to the attribute `out_sample_residuals`. Out of sample</span>
<span class="sd">    residuals are meant to be calculated using observations that did not</span>
<span class="sd">    participate in the training process.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    residuals : dict</span>
<span class="sd">        Dictionary of numpy ndarrays with the residuals of each model in the</span>
<span class="sd">        form {step: residuals}. If len(residuals) &gt; 1000, only a random </span>
<span class="sd">        sample of 1000 values are stored.</span>

<span class="sd">    append : bool, default `True`</span>
<span class="sd">        If `True`, new residuals are added to the once already stored in the</span>
<span class="sd">        attribute `out_sample_residuals`. Once the limit of 1000 values is</span>
<span class="sd">        reached, no more values are appended. If False, `out_sample_residuals`</span>
<span class="sd">        is overwritten with the new residuals.</span>

<span class="sd">    transform : bool, default `True`</span>
<span class="sd">        If `True`, new residuals are transformed using self.transformer_y.</span>

<span class="sd">    random_state : int, default `123`</span>
<span class="sd">        Sets a seed to the random sampling for reproducible output.</span>

<span class="sd">    Returns </span>
<span class="sd">    -------</span>
<span class="sd">    self</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">residuals</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="ow">or</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">residuals</span><span class="o">.</span><span class="n">values</span><span class="p">()):</span>
        <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;`residuals` argument must be a dict of numpy ndarrays in the form &quot;</span>
            <span class="s2">&quot;`{step: residuals}`. &quot;</span> 
            <span class="sa">f</span><span class="s2">&quot;Got </span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="n">residuals</span><span class="p">)</span><span class="si">}</span><span class="s2">.&quot;</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">fitted</span><span class="p">:</span>
        <span class="k">raise</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">NotFittedError</span><span class="p">(</span>
            <span class="p">(</span><span class="s2">&quot;This forecaster is not fitted yet. Call `fit` with appropriate &quot;</span>
             <span class="s2">&quot;arguments before using `set_out_sample_residuals()`.&quot;</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span> <span class="o">=</span> <span class="p">{</span><span class="n">step</span><span class="p">:</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)}</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">())):</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">            Only residuals of models (steps) </span>
<span class="s2">            </span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span><span class="o">.</span><span class="n">intersection</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">()))</span><span class="si">}</span><span class="s2"> </span>
<span class="s2">            are updated.</span>
<span class="s2">            &quot;&quot;&quot;</span>
        <span class="p">)</span>

    <span class="n">residuals</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span><span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">residuals</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">key</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">transform</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Argument `transform` is set to `False` but forecaster was trained &quot;</span>
             <span class="sa">f</span><span class="s2">&quot;using a transformer </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="si">}</span><span class="s2">. Ensure that the new residuals &quot;</span>
             <span class="sa">f</span><span class="s2">&quot;are already transformed or set `transform=True`.&quot;</span><span class="p">)</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">transform</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Residuals will be transformed using the same transformer used &quot;</span>
             <span class="sa">f</span><span class="s2">&quot;when training the forecaster (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="si">}</span><span class="s2">). Ensure the &quot;</span>
             <span class="sa">f</span><span class="s2">&quot;new residuals are on the same scale as the original time series.&quot;</span><span class="p">)</span>
        <span class="p">)</span>
        <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">residuals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
            <span class="n">residuals</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">transform_series</span><span class="p">(</span>
                                 <span class="n">series</span>            <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">Series</span><span class="p">(</span><span class="n">value</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;residuals&#39;</span><span class="p">),</span>
                                 <span class="n">transformer</span>       <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="p">,</span>
                                 <span class="n">fit</span>               <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
                                 <span class="n">inverse_transform</span> <span class="o">=</span> <span class="kc">False</span>
                             <span class="p">)</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

    <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="n">residuals</span><span class="o">.</span><span class="n">items</span><span class="p">():</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1000</span><span class="p">:</span>
            <span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="o">=</span><span class="n">random_state</span><span class="p">)</span>
            <span class="n">value</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">choice</span><span class="p">(</span><span class="n">a</span><span class="o">=</span><span class="n">value</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">replace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

        <span class="k">if</span> <span class="n">append</span> <span class="ow">and</span> <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
            <span class="n">free_space</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1000</span> <span class="o">-</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="p">[</span><span class="n">key</span><span class="p">]))</span>
            <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">value</span><span class="p">)</span> <span class="o">&lt;</span> <span class="n">free_space</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="p">[</span><span class="n">key</span><span class="p">],</span>
                            <span class="n">value</span>
                        <span class="p">))</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">value</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">hstack</span><span class="p">((</span>
                            <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="p">[</span><span class="n">key</span><span class="p">],</span>
                            <span class="n">value</span><span class="p">[:</span><span class="n">free_space</span><span class="p">]</span>
                        <span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">out_sample_residuals</span><span class="p">[</span><span class="n">key</span><span class="p">]</span> <span class="o">=</span> <span class="n">value</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h3 id="skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.set_params" class="doc doc-heading">
<code class="highlight language-python"><span class="n">set_params</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span></code>


<a href="#skforecast.ForecasterAutoregDirect.ForecasterAutoregDirect.ForecasterAutoregDirect.set_params" class="headerlink" title="Permanent link">&para;</a></h3>

    <div class="doc doc-contents ">

      <p>Set new values to the parameters of the scikit learn model stored in the</p>
<p>forecaster. It is important to note that all models share the same 
configuration of parameters and hyperparameters.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>params</code></td>
        <td><code>dict</code></td>
        <td><p>Parameters values.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoregDirect/ForecasterAutoregDirect.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">set_params</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> 
    <span class="n">params</span><span class="p">:</span> <span class="nb">dict</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Set new values to the parameters of the scikit learn model stored in the</span>
<span class="sd">    forecaster. It is important to note that all models share the same </span>
<span class="sd">    configuration of parameters and hyperparameters.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    params : dict</span>
<span class="sd">        Parameters values.</span>

<span class="sd">    Returns </span>
<span class="sd">    -------</span>
<span class="sd">    self</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span> <span class="o">=</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">set_params</span><span class="p">(</span><span class="o">**</span><span class="n">params</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">regressors_</span> <span class="o">=</span> <span class="p">{</span><span class="n">step</span><span class="p">:</span> <span class="n">clone</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">)</span> <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">steps</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)}</span>
</code></pre></div>
        </details>
    </div>

  </div>





  </div>

    </div>

  </div>



  <div class="doc doc-object doc-method">



<h2 id="skforecast.ForecasterAutoreg.ForecasterAutoreg.ForecasterAutoreg._create_lags" class="doc doc-heading">
<code class="highlight language-python"><span class="n">_create_lags</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-private"><code>private</code></small>
  </span>

<a href="#skforecast.ForecasterAutoreg.ForecasterAutoreg.ForecasterAutoreg._create_lags" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

      <p>Transforms a 1d array into a 2d array (X) and a 1d array (y). Each row</p>
<p>in X is associated with a value of y and it represents the lags that
precede it.</p>
<p>Notice that, the returned matrix X_data, contains the lag 1 in the first
column, the lag 2 in the second column and so on.</p>

<p><strong>Parameters:</strong></p>
<table>
  <thead>
    <tr>
      <th>Name</th>
      <th>Type</th>
      <th>Description</th>
      <th>Default</th>
    </tr>
  </thead>
  <tbody>
      <tr>
        <td><code>y</code></td>
        <td><code>ndarray</code></td>
        <td><p>Training time series.</p></td>
        <td><em>required</em></td>
      </tr>
  </tbody>
</table>
<p><strong>Returns:</strong></p>
<table>
  <thead>
    <tr>
      <th>Type</th>
      <th>Description</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>Tuple[numpy.ndarray, numpy.ndarray]</code></td>
      <td><p>2d numpy array with the lagged values (predictors).</p></td>
    </tr>
  </tbody>
</table>
        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoreg/ForecasterAutoreg.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="nf">_create_lags</span><span class="p">(</span>
    <span class="bp">self</span><span class="p">,</span> 
    <span class="n">y</span><span class="p">:</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="p">]:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;       </span>
<span class="sd">    Transforms a 1d array into a 2d array (X) and a 1d array (y). Each row</span>
<span class="sd">    in X is associated with a value of y and it represents the lags that</span>
<span class="sd">    precede it.</span>

<span class="sd">    Notice that, the returned matrix X_data, contains the lag 1 in the first</span>
<span class="sd">    column, the lag 2 in the second column and so on.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------        </span>
<span class="sd">    y : 1d numpy ndarray</span>
<span class="sd">        Training time series.</span>

<span class="sd">    Returns </span>
<span class="sd">    -------</span>
<span class="sd">    X_data : 2d numpy ndarray, shape (samples - max(self.lags), len(self.lags))</span>
<span class="sd">        2d numpy array with the lagged values (predictors).</span>

<span class="sd">    y_data : 1d numpy ndarray, shape (samples - max(self.lags),)</span>
<span class="sd">        Values of the time series related to each row of `X_data`.</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">n_splits</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span>
    <span class="k">if</span> <span class="n">n_splits</span> <span class="o">&lt;=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
            <span class="sa">f</span><span class="s2">&quot;The maximum lag (</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="si">}</span><span class="s2">) must be less than the length &quot;</span>
            <span class="sa">f</span><span class="s2">&quot;of the series (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span><span class="si">}</span><span class="s2">).&quot;</span>
        <span class="p">)</span>

    <span class="n">X_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">(</span><span class="n">n_splits</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">)),</span> <span class="n">fill_value</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">nan</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">float</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">lag</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="p">):</span>
        <span class="n">X_data</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span> <span class="o">-</span> <span class="n">lag</span><span class="p">:</span> <span class="o">-</span><span class="n">lag</span><span class="p">]</span>

    <span class="n">y_data</span> <span class="o">=</span> <span class="n">y</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">max_lag</span><span class="p">:]</span>

    <span class="k">return</span> <span class="n">X_data</span><span class="p">,</span> <span class="n">y_data</span>
</code></pre></div>
        </details>
    </div>

  </div>



  <div class="doc doc-object doc-method">



<h2 id="skforecast.ForecasterAutoreg.ForecasterAutoreg.ForecasterAutoreg.__repr__" class="doc doc-heading">
<code class="highlight language-python"><span class="fm">__repr__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span></code>

  <span class="doc doc-properties">
      <small class="doc doc-property doc-property-special"><code>special</code></small>
  </span>

<a href="#skforecast.ForecasterAutoreg.ForecasterAutoreg.ForecasterAutoreg.__repr__" class="headerlink" title="Permanent link">&para;</a></h2>

    <div class="doc doc-contents first">

      <p>Information displayed when a ForecasterAutoreg object is printed.</p>

        <details class="quote">
          <summary>Source code in <code>skforecast/ForecasterAutoreg/ForecasterAutoreg.py</code></summary>
          <div class="highlight"><pre><span></span><code><span class="k">def</span> <span class="fm">__repr__</span><span class="p">(</span>
    <span class="bp">self</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">str</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Information displayed when a ForecasterAutoreg object is printed.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="p">,</span> <span class="n">sklearn</span><span class="o">.</span><span class="n">pipeline</span><span class="o">.</span><span class="n">Pipeline</span><span class="p">):</span>
        <span class="n">name_pipe_steps</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">name</span> <span class="o">+</span> <span class="s2">&quot;__&quot;</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">named_steps</span><span class="o">.</span><span class="n">keys</span><span class="p">())</span>
        <span class="n">params</span> <span class="o">=</span> <span class="p">{</span><span class="n">key</span> <span class="p">:</span> <span class="n">value</span> <span class="k">for</span> <span class="n">key</span><span class="p">,</span> <span class="n">value</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">get_params</span><span class="p">()</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> \
                  <span class="k">if</span> <span class="n">key</span><span class="o">.</span><span class="n">startswith</span><span class="p">(</span><span class="n">name_pipe_steps</span><span class="p">)}</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">params</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="o">.</span><span class="n">get_params</span><span class="p">(</span><span class="n">deep</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">info</span> <span class="o">=</span> <span class="p">(</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="s1">&#39;=&#39;</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="nb">len</span><span class="p">(</span><span class="nb">type</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span><span class="o">.</span><span class="vm">__name__</span><span class="p">)</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Regressor: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">regressor</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Lags: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">lags</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Transformer for y: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer_y</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Transformer for exog: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">transformer_exog</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Window size: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">window_size</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Weight function included: </span><span class="si">{</span><span class="kc">True</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">weight_func</span><span class="w"> </span><span class="ow">is</span><span class="w"> </span><span class="ow">not</span><span class="w"> </span><span class="kc">None</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="kc">False</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Exogenous included: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">included_exog</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Type of exogenous variable: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">exog_type</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Exogenous variables names: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">exog_col_names</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Training range: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">training_range</span><span class="o">.</span><span class="n">to_list</span><span class="p">()</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">fitted</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="kc">None</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Training index type: </span><span class="si">{</span><span class="nb">str</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">index_type</span><span class="p">)</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;.&#39;</span><span class="p">)[</span><span class="o">-</span><span class="mi">1</span><span class="p">][:</span><span class="o">-</span><span class="mi">2</span><span class="p">]</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">fitted</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="kc">None</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Training index frequency: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">index_freq</span><span class="w"> </span><span class="k">if</span><span class="w"> </span><span class="bp">self</span><span class="o">.</span><span class="n">fitted</span><span class="w"> </span><span class="k">else</span><span class="w"> </span><span class="kc">None</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Regressor parameters: </span><span class="si">{</span><span class="n">params</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;fit_kwargs: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_kwargs</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Creation date: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">creation_date</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Last fit date: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">fit_date</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Skforecast version: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">skforcast_version</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Python version: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">python_version</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
        <span class="sa">f</span><span class="s2">&quot;Forecaster id: </span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="n">forecaster_id</span><span class="si">}</span><span class="s2"> </span><span class="se">\n</span><span class="s2">&quot;</span>
    <span class="p">)</span>

    <span class="k">return</span> <span class="n">info</span>
</code></pre></div>
        </details>
    </div>

  </div>


  




                
              </article>
            </div>
          
          
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            Back to top
          </a>
        
      </main>
      
        <footer class="md-footer">
  
    
    <nav class="md-footer__inner md-grid" aria-label="Footer" >
      
        
        <a href="ForecasterAutoregCustom.html" class="md-footer__link md-footer__link--prev" aria-label="Previous: ForecasterAutoregCustom" rel="prev">
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
          </div>
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Previous
              </span>
              ForecasterAutoregCustom
            </div>
          </div>
        </a>
      
      
        
        <a href="ForecasterMultiSeries.html" class="md-footer__link md-footer__link--next" aria-label="Next: ForecasterMultiSeries" rel="next">
          <div class="md-footer__title">
            <div class="md-ellipsis">
              <span class="md-footer__direction">
                Next
              </span>
              ForecasterMultiSeries
            </div>
          </div>
          <div class="md-footer__button md-icon">
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
          </div>
        </a>
      
    </nav>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
      <div class="md-consent" data-md-component="consent" id="__consent" hidden>
        <div class="md-consent__overlay"></div>
        <aside class="md-consent__inner">
          <form class="md-consent__form md-grid md-typeset" name="consent">
            

  
    
  


  
    
  



  

<h4>Cookie consent</h4>
<p>We use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they're searching for. With your consent, you're helping us to make our documentation better.</p>
<input type="checkbox" class="md-toggle" id="__settings">
<div class="md-consent__settings">
  <ul class="task-list">
    
      
        
        
      
      <li class="task-list-item">
        <label class="task-list-control">
          <input type="checkbox" name="analytics" checked>
          <span class="task-list-indicator"></span>
          Google Analytics
        <label>
      </li>
    
      
        
        
      
      <li class="task-list-item">
        <label class="task-list-control">
          <input type="checkbox" name="github" checked>
          <span class="task-list-indicator"></span>
          GitHub
        <label>
      </li>
    
  </ul>
</div>
<div class="md-consent__controls">
  
    
      <button class="md-button md-button--primary">Accept</button>
    
    
    
  
    
    
    
      <label class="md-button" for="__settings">Manage settings</label>
    
  
</div>
          </form>
        </aside>
      </div>
      <script>var consent=__md_get("__consent");if(consent)for(var input of document.forms.consent.elements)input.name&&(input.checked=consent[input.name]||!1);else"file:"!==location.protocol&&setTimeout(function(){document.querySelector("[data-md-component=consent]").hidden=!1},250);var action,form=document.forms.consent;for(action of["submit","reset"])form.addEventListener(action,function(e){if(e.preventDefault(),"reset"===e.type)for(var n of document.forms.consent.elements)n.name&&(n.checked=!1);console.log(new FormData(form)),__md_set("__consent",Object.fromEntries(Array.from(new FormData(form).keys()).map(function(e){return[e,!0]}))),location.hash="",location.reload()})</script>
    
    <script id="__config" type="application/json">{"base": "..", "features": ["navigation.tabs", "navigation.tabs.sticky", "navigation.sections", "navigation.expand", "navigation.top"], "search": "../assets/javascripts/workers/search.5bf1dace.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.config.lang": "en", "search.config.pipeline": "trimmer, stopWordFilter", "search.config.separator": "[\\s\\-]+", "search.placeholder": "Search", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version.title": "Select version"}, "version": {"provider": "mike"}}</script>
    
    
      <script src="../assets/javascripts/bundle.37e9125f.min.js"></script>
      
    
  </body>
</html>